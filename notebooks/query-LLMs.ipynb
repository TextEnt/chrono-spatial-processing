{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aisuite as ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ai.Client()\n",
    "client.configure({\n",
    "  \"ollama\" : {\n",
    "    \"timeout\": 600,\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test `aisuite` with dummy prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Respond in Pirate English. Always try to include the phrase - No rum No fun.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a joke about Captain Jack Sparrow\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               ID              SIZE      MODIFIED          \n",
      "phi4:latest        ac896e5b8b34    9.1 GB    55 seconds ago       \n",
      "gemma2:9b          ff02c3702f32    5.4 GB    41 minutes ago       \n",
      "llama3.2:latest    a80c4f17acd5    2.0 GB    About an hour ago    \n",
      "deepseek-r1:8b     28f8fd6cdc67    4.9 GB    2 hours ago          \n",
      "llama3.3:latest    a6eb4748fd29    42 GB     3 weeks ago          \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    #\"ollama:deepseek-r1:8b\",\n",
    "    #\"ollama:llama:3.3:latest\",\n",
    "    \"ollama:llama3.2:latest\",\n",
    "    \"ollama:gemma2:9b\",\n",
    "    \"ollama:phi4:latest\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "replies = {}\n",
    "\n",
    "for selected_model in models:\n",
    "    response = client.chat.completions.create(model=selected_model, messages=messages)\n",
    "    replies[selected_model] = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: ollama:llama3.2:latest; reply's length = 243\n",
      "Model: ollama:gemma2:9b; reply's length = 304\n"
     ]
    }
   ],
   "source": [
    "for k,v in replies.items():\n",
    "    print(f\"Model: {k}; reply's length = {len(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ollama:llama3.2:latest': \"Yer lookin' fer a joke about that scurvy dog, eh? Alright then, listen close:\\n\\nWhy did Captain Jack Sparrow bring a ladder aboard his ship?\\n\\nBecause he heard the drinks were on the house! Arrr, no rum, no fun!\",\n",
       " 'ollama:gemma2:9b': \"Ahoy, matey! Ye want a tale 'bout ol' Jack Sparrow? \\n\\nGather 'round and listen close:\\n\\nWhy did Captain Jack Sparrow always carry two compasses? \\n\\nTo be sure he wasn't lost at sea...and to have one to point the way to the nearest grog stash! No rum, no fun, ye hear?  üçªüíÄ\\n\\n\\n\",\n",
       " 'ollama:phi4:latest': 'Ahoy there, matey! Gather \\'round for a tale o\\' ol\\' Cap\\'n Jack Sparrow!\\n\\nSo, what happens when you mix Captain Jack Sparrow with a chicken?\\n\\nYou get... \"Cluckin\\' up the wrong ship!\"\\n\\nArrr, no rum, no fun! But remember, ye never know where yer adventure will take ye next!'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query LLMs with real TextEnt data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for each document, load the pre-generated summary\n",
    "- based on the summary, for each doc generate 3 prompts (metadata, metadata + incipit, metadata + summary)\n",
    "- iterate over doc, iterate over prompts per doc, iterate over models, then query with triples (docu, model, prompt)\n",
    "\n",
    "- start with a spacy document\n",
    "- load the corresponding pre-generated summary\n",
    "- define a `build_prompts` function that takes a `spacy_doc` as input and returns a list of tuples `('prompt-id', 'prompt-message')` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "def build_summary_prompt(spacy_doc: Doc) -> str:\n",
    "    \"\"\"\n",
    "    Builds a summary prompt based on a spaCy document.\n",
    "\n",
    "    Args:\n",
    "        spacy_doc (Doc): A spaCy document object containing the text and metadata.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted summary prompt.\n",
    "\n",
    "    The summary is loaded from a JSON file located in the \"../data/summaries\" directory.\n",
    "    The filename of the summary is derived from the 'document_id' stored in the user_data attribute of the spaCy document.\n",
    "    \"\"\"\n",
    "    summaries_path = Path(\"../data/summaries\")\n",
    "    doc_summary_path = summaries_path / f\"{spacy_doc.user_data['document_id']}_summary.json\"\n",
    "\n",
    "    # load base prompt\n",
    "    with open(\"../data/prompts/base_prompt.txt\", \"r\") as file:\n",
    "        base_prompt = file.read()\n",
    "\n",
    "    # load the pre-computed summary from its JSON file\n",
    "    with doc_summary_path.open('r', encoding='utf-8') as file:\n",
    "        summary = json.load(file)\n",
    "\n",
    "    # JSON to pretty string\n",
    "    summary_as_string = json.dumps(summary, indent=2, ensure_ascii=False)\n",
    "    return base_prompt.format(document_summary=summary_as_string)\n",
    "\n",
    "def build_prompts(spacy_doc: Doc) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Builds prompts based on a spaCy document.\n",
    "\n",
    "    Args:\n",
    "        spacy_doc (Doc): A spaCy document object containing the text and metadata.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, str]]: A list of tuples where each tuple contains a prompt ID and its text.    \n",
    "    \"\"\"\n",
    "    prompts = []\n",
    "    prompts.append(\n",
    "          ('prompt-w-summary', build_summary_prompt(spacy_doc))\n",
    "    )\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_generate_prompts(spacy_docs: List[Doc], output_path: Path) -> None:\n",
    "    for spacy_doc in tqdm(spacy_docs, desc=\"Pre-generating prompts\"):\n",
    "        doc_id = spacy_doc.user_data[\"document_id\"]\n",
    "        prompts = build_prompts(spacy_doc)\n",
    "\n",
    "        # Define the path to the directory\n",
    "        directory_path = output_path / doc_id\n",
    "\n",
    "        # Check if the directory exists\n",
    "        if not directory_path.exists():\n",
    "            directory_path.mkdir(parents=True, exist_ok=True) # Create the directory if it does not exist\n",
    "\n",
    "        for prompt_id, prompt in prompts:\n",
    "            print(f\"Writing prompt {prompt_id} for document {doc_id}\")\n",
    "            with open(output_path / doc_id / f\"{doc_id}_{prompt_id}.txt\", \"w\") as file:\n",
    "                file.write(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from textentlib.utils import load_or_create_corpus, nlp_model_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACY_CORPUS_SERIALIZED_PATH = Path(\"../data/corpus_24012025.spacy\")\n",
    "PRE_GENERATED_PROMPTS_PATH = Path(\"../data/prompts/pregenerated\")    \n",
    "SAMPLE_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded serialize spacy corpus from ../data/corpus_24012025.spacy\n",
      "Number of documents in the corpus: 594\n",
      "Number of entities in the corpus: 287389\n",
      "Number of tokens in the corpus: 12885306\n"
     ]
    }
   ],
   "source": [
    "spacy_corpus = load_or_create_corpus(SPACY_CORPUS_SERIALIZED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = spacy_corpus.get_docs(nlp_model_fr.vocab)\n",
    "docs = list(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# - we may want to exclude documents in the validation set\n",
    "# - we may want to exclude documents that are very long (> 150k tokens)\n",
    "sampled_docs = random.sample(docs, SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prompt-w-summary',\n",
       "  'Look at the following JSON object describing a literary text in French (XVII century). It contains basic metadata about the text (author, title, publication date).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"La Croix, C\",\\n    \"title\": \"La Clim√®ne : tragi-com√©die pastorale ; avec plusieurs Autres oeuvres du mesme autheur / par le Sr de La Croix\",\\n    \"publication_date\": \"1629\",\\n    \"document_id\": \"bpt6k1097754\"\\n  },\\n  \"context\": {\\n    \"people\": {\\n      \"top_1_person\": {\\n        \"entity\": {\\n          \"label\": \"Climene\",\\n          \"frequency\": 3\\n        },\\n        \"related_sentences\": [\\n          \"J\\'afait e√ªt trois ans un glorieus troph√©e D\\' mes plus beaus d√©sirs aux yeus de Clorife, J\\'honore ses beaut√©s, ie reuere ses lois, Je l\\'adore idolatre, et ainsi vois toutefois Qu\\'ingrate elle n\\'arien dans l\\'√¢me que Silandre Lequel (√¥ juste ciel) ne la veut point entendre, Et qui pour sa Clim√®ne amant rempli d\\'ardeur Pour Clorife n\\'est qu\\'une morte froideur, Qu\\'une insensible marbre, et qui l‚Äô oreille bouche Auser sa mots que lui dit sa suppliate bouche, Cherissant contre moi son aise et son repos, Voyant ce us m√©priser ses propos, Ne s\\'esmouuoir que quelque a peinte Comme elle inuoquoit dolente plainte, Afin de adoucir, ay tenteÃÅ par effort De la lui faire aimer, ou lui donner la mo, Et dans la fin du , si √¥ m√™me Ne en e√ªt empescheÃÅ, il e√ªt crieÃÅ, Ie aime, Elle me fuit pourtant cruelle, et ne veut point DoÃÉner quelquerelasche au trauail qui me point.\",\\n          \"Ma volont√© ne peut √™tre √† l\\'amour cortraire, J\\'aime mieus en ce lieu comme pauvre √©tranger Para√Ætre sous le nom et l\\'habit de Berger, Poss√©dant ma Clim√®ne en plaine jouissance, Que d\\'avoir les honneurs que me doit ma naissaÃÉTout ce que le malheur me fait sentir de mal, sauce, Serviteur comme moi d\\'un Berger du village, Mais dont les qualit√©s ont beaucoup d\\'auantaEt lequel d√©mentant sa vile extraction Se conduit tellement en son affection, Que ses rares vertus dont Climene est √©prise, Pourraient bien ruiner toute mon entreprise: Je craignais Liridas √† cause de ses biens, Qui pouvaient attirer S√©mire en ses liens, Mais gr√¢ce √† mon bon heur, une m√©lancolie A tellement chang√© son amour en folie, Que ses sens √©gar√©s, son faible esprit d√©mis Fait rire en m√™me temps et pleurer ses amis.\",\\n          \"Ne partagea tamais le temps auecla nuit, Iluit Ie veux h√¢tir un temple ou mon amour Seigneur pleure, Qui sera tout aupr√®s de ma triste demeure, Attendant que le ciel √©mu de mes tourments, Me loge au saint s√©jour des fid√®les amants, Les pleurs que j\\'√©pandra seront le sacrifice Parra commencera mon fun√®bre service, Le portrait de Clim√®ne appendu deuant moi, Ieluy ferai saÃÉs cesse hoÃÉmage de ma fo I steindre Mon c≈ìur br√ªlant d\\'une fi qui ne pourra s\\'ePar les eaus de mes yeus ne se feraque Par, Offrant les pour parfun de tels us De possible m sort deuiendra plus heureus, Que si la seule mortfin√Æt monaduanture, Et doit suire mes les douleurs que endure, Si iamais quelque Amant accableÃÅ de soucy, Vient visiter ma grotte, il y verra ceci.\",\\n          \"Silandre n\\'ayant pu fl√©chir Clim√®ne, implore le secours d\\'un Magicien, duquel il re√ßoit un bracelet charm√© sans en scÃßauoir la vertu, et lequel pos√© sur le bras de Clim√®ne, la rend peu √† peu comme percluse de tous ses membres, et en fin l\\'assoupit de telle fa√ßon, qu\\'√©tant estim√©e morte, m√™me de Silandre, elle est mise en un cercueil, ayant auparauaÃÉt cet assoupissement de deuant S√©mire son pere putatif, l\\'amour qu\\'elle avait pour Alcidor Silandre se veut venger sur le Magicien, qui s\\'excusant de ne lui avoir dit le secret, toujours d√©couvre la force du charme, et lui donne d\\'une eau, de laquelle Silandre ayant mouill√© le visage de Clim√®ne, elle revient de p√¢moison.\",\\n          \"Florimant l\\'ayant vue en est tellement amoureus, que sa passion le fait arr√™ter pour prendre l\\'habit de Berger et le nom d\\'Alcidor Lidias son pu√Æn√© voyant sa longuc absence, et que Phalante son p√®re en √©tait au d√©sespoir, obtient un an de cong√© pour chercher son fr√®re: passant par ce m√™me lieu la beaut√© de Clim√®ne fait un m√™me effet sur moi, si bien qu\\'il se d√©guise pareillement en Berger et se donne le nom de Silandre il a pour rivaus Alcidor son fr√®re, qu\\'il ne reconoist point et duquel il n\\'est point con√ßu, et le Berger Lidas qui d√©sesp√©r√© de poss√©der Clim√®ne, perd l\\'esprit et fait des extravagances √©tranges.\"\\n        ]\\n      },\\n      \"top_5_persons\": [\\n        \"Climene\",\\n        \"Seigneur\",\\n        \"Pluton\",\\n        \"Berg√®re\",\\n        \"LECHO\"\\n      ]\\n    },\\n    \"places\": {\\n      \"top_1_place\": {\\n        \"entity\": {\\n          \"label\": \"Paris\",\\n          \"frequency\": 3\\n        },\\n        \"related_sentences\": [\\n          \"objets pour esmouuoir mes plainSi entre dans h il me semble de voir [tes, La fille de Ceres que Pluton \\' a, Mant de delaÃÄ, et en fin hors haleine, Tombe sous le pouvoir de ce Dieu qui l\\'emmeine, Si tu suis dans Paris, ces riches b√¢timents Ne me peuvent donner de divertissements, Et toutes ces beaut√©s dont son fleuve se parure Qui jusqu\\'aus moindres traits n\\'oÃÉt riends qui ne soit Me rendant satisfait, et non pas Amoureus, Ne chang point pourtant mon √©tat malheureus, L\\'une peut bien avoir un air dedans la face Qui la fera louer pour avoir bonne gr√¢ce, Et ie nos rencontrer en quelque autre un bel s, Que l\\'on peut sans flatter appeler votre soleil,\",\\n          \"Conseillers les Gens tenan ts Cour de Parlement de Paris, Preuost dudit lieu, S√©n√©chal de Lyon, Poitou, Berry, Champagne, Et dAnjou, et du Maine, et √† tous nos autres Iusticiers autres Justiciers ou leurs Lieutenants, Salut et dilection.\",\\n          \"Donn√© a Paris le AAstij jour de Novembre, mil six cens vingt-huit, et de notre R√®gne le dixneufiesme.\"\\n        ]\\n      },\\n      \"top_5_places\": [\\n        \"Paris\",\\n        \"France\",\\n        \"Seine\",\\n        \"Hollande\",\\n        \"Anra\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nYour role is...\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"reason\": \"why has been chosen\",\\n    \"period\": \"period_identified\",\\n    \"timeframe_start\": \"ISO value of the start\",\\n    \"timeframe_end\": \"ISO value of the end\"\\n}\\n```')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_prompts(sampled_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-generating prompts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 592.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prompt prompt-w-summary for document bpt6k1097754\n",
      "Writing prompt prompt-w-summary for document bpt6k5738753j\n",
      "Writing prompt prompt-w-summary for document bpt6k1090193n\n",
      "Writing prompt prompt-w-summary for document bpt6k8568847\n",
      "Writing prompt prompt-w-summary for document btv1b86221054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pre_generate_prompts(sampled_docs, PRE_GENERATED_PROMPTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
