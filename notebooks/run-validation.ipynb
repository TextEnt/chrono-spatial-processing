{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run validation of LLM-judge evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import aisuite as ai\n",
    "from pathlib import Path\n",
    "from textentlib.utils import read_configuration\n",
    "from textentlib.llm_utils import fetch_prompts, try_extract_json_from_text\n",
    "from textentlib.llm_utils import prepare_evaluation_dataframe, query_llm, query_llm_judge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_configuration(Path('../data/config.yaml'))\n",
    "llms = config['validation']['models']\n",
    "base_path = Path('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/')\n",
    "gt_path = base_path / config['validation']['groundtruth_path']\n",
    "pregen_prompts_path = base_path / config['validation']['pregenerated_prompts_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama:phi4-mini:latest\n",
      "ollama:gemma3:12b\n",
      "ollama:mistral-small:24b\n",
      "ollama:deepseek-r1:14b\n",
      "ollama:deepseek-r1:32b\n",
      "openai:o1-mini\n",
      "openai:gpt-4o\n",
      "deepseek:deepseek-reasoner\n",
      "anthropic:claude-3-7-sonnet-20250219\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(llms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get LLM predictions on validation documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_llm_responses_path = Path(base_path / config['validation']['responses_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"['Unnamed: 11', 'Unnamed: 12'] not found in axis\"\n"
     ]
    }
   ],
   "source": [
    "# this should return only the test (validation) set (n=5 docs)\n",
    "validation_docs, df_validation_data = prepare_evaluation_dataframe(\n",
    "    llm_response_path=validation_llm_responses_path,\n",
    "    gt_annotations_path=gt_path,\n",
    "    gt_metadata_path=gt_path,\n",
    "    split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_data.to_csv('../data/evaluation_data.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_docs = ['bpt6k10901623',\n",
    " 'bpt6k9807756q',\n",
    " 'bpt6k852913n',\n",
    " 'bpt6k5772699f',\n",
    " 'bpt6k1090242p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_requests = fetch_prompts(Path(pregen_prompts_path), validation_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llm_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LLMrequest(prompt_id='prompt-excerpt.txt', document_id='bpt6k10901623', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k10901623/bpt6k10901623_prompt-excerpt.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date), while the `excerpt` property contains an excerpt of 400 words sampled from around the middle of the document.\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Boisrobert, François de\",\\n    \"title\": \"Théodore, Reyne de Hongrie, tragi-comédie\",\\n    \"publication_date\": \"1658\",\\n    \"document_id\": \"bpt6k10901623\"\\n  },\\n  \"excerpt\": \"re; Oui j\\'ai pitié de vous, Prince, et je vous promets, Si vous vous repentez, de n\\'y penser jamais, Je me reprocherai cette ardeur enragée, Comme si on l\\'avais bizarrement songée, Revenez donc à vous, ouvrez, ouurez les yeux, Et voyez où vous porte un désir furieux, Seriez-vous pas perdu si le Roi qui vous aime, Pouvait être averti de ce désordre extrême, Savez-vous qui ie suis, me connaissez-vou\"\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-metadata.txt', document_id='bpt6k10901623', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k10901623/bpt6k10901623_prompt-metadata.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Boisrobert, François de\",\\n    \"title\": \"Théodore, Reyne de Hongrie, tragi-comédie\",\\n    \"publication_date\": \"1658\",\\n    \"document_id\": \"bpt6k10901623\"\\n  }\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-summary.txt', document_id='bpt6k10901623', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k10901623/bpt6k10901623_prompt-summary.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date), while the `context` property contains information about the people and places that are most frequently mentioned in the play (such as label, mention frequency, and salient sentences where it appears).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Boisrobert, François de\",\\n    \"title\": \"Théodore, Reyne de Hongrie, tragi-comédie\",\\n    \"publication_date\": \"1658\",\\n    \"document_id\": \"bpt6k10901623\"\\n  },\\n  \"context\": {\\n    \"people\": {\\n      \"top_1_person\": {\\n        \"entity\": {\\n          \"label\": \"RAMÉE\",\\n          \"frequency\": 1\\n        },\\n        \"related_sentences\": [\\n          \"Me voyant emporté tu pouvais m\\'écouter, Mais tu ne devais pas si vite exécuter, colère aueugle, aueuglement suiuie, Me va coûter honneur, le repos et la vie, serviteur fidèle agit plus prudemment, \\\\nRAMÉE\\\\n Vous voulez qu\\'on vous serve en tout aveuglément : Je voyais bien, Seigneur, que votre ordre était Jude, Mais tu craignais l\\'effet de votre promptitude, J\\'en ai vu dans la Cour l\\'exemple dangereux, J\\'ai vu périr des Grands, tu me règle par eux, LE ROY.\",\\n          \"LE ROY Cet ordre est surprenant, il est grand, il t\\'étonne, Mais, Ramèse, en un mot il faut l\\'exécuter, De ta fidélité Seigneur ne saurais douter, Va, lcrime est connu, \\'ai tout su de mon frère, La Reylie a dals son tœur commis un Adultère, Elle est digne de mort, va donc de ce pas, Exécuter mon ordre et ne réplique pas. \\\\nRAMÉE\\\\n J\\'obéirai Seigneur, LE ROY.\",\\n          \"Puis que ta main trop prompte a suivi ma pensée, Condamnons seulement celui qui l\\'a poussée, Tu suis un ordre injuste, et j\\'excuse ton bras, Mais, traître que je suis, tu ne m\\'excuse pas, Een le me parvome un coup n\\'étable. \\\\nRAMÉE\\\\n \",\\n          \"que m\\'apprendstu? \\\\nRAMÉE\\\\n u’on fait un double outrage à la même vertu, J\\'ai peur que ce récit, Seigneur, ne vous accable, 4 Vous voyez que ici tremble au seul nom du cou.\",\\n          \"Cette lettre est du Prince, \\\\nRAMÉE\\\\n Elle est du suborneur: Comme il a vainement attaqué son honneur, Elle l\\'a menacé, mais il l\\'a prévenue, Sans songer que sa lettre un jour serait connue;\"\\n        ]\\n      },\\n      \"top_5_persons\": [\\n        \"RAMÉE\",\\n        \"Irene\",\\n        \"Irene\",\\n        \"Théodore\",\\n        \"Irène\"\\n      ]\\n    },\\n    \"places\": {\\n      \"top_1_place\": {\\n        \"entity\": {\\n          \"label\": \"Asie\",\\n          \"frequency\": 1\\n        },\\n        \"related_sentences\": [\\n          \"ennemis défaits attendent du secours, Mais pour le repos de nos jours, Amurat est-pressé de passer en Asie, Je ne crains donc plus rien de l\\'armée ennemie.\"\\n        ]\\n      },\\n      \"top_5_places\": [\\n        \"Asie\",\\n        \"Moni\",\\n        \"Jap\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-excerpt.txt', document_id='bpt6k1090242p', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k1090242p/bpt6k1090242p_prompt-excerpt.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date), while the `excerpt` property contains an excerpt of 400 words sampled from around the middle of the document.\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": null,\\n    \"title\": \"Tite et Titus, ou Critique sur les Berenices, comédie\",\\n    \"publication_date\": \"1673\",\\n    \"document_id\": \"bpt6k1090242p\"\\n  },\\n  \"excerpt\": \" pas fort extraordinaist buser une fille souz promesse de mariage. On voit plus d\\'un moqueur Enée, Et plus d\\'une folle Didon Couvrer les feux de Cupidon Souz les cendres de L\\'hyménée. Voici quelque chose déplus étrange; il n\\'est rien de si touchant ainsi de si tendre que les choses qu\\'il dir il sa Berenice dans cette occalion, il semble tout à coup qu\\'il va expirer d\\'amour pour elle, enfin il est \"\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-metadata.txt', document_id='bpt6k1090242p', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k1090242p/bpt6k1090242p_prompt-metadata.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": null,\\n    \"title\": \"Tite et Titus, ou Critique sur les Berenices, comédie\",\\n    \"publication_date\": \"1673\",\\n    \"document_id\": \"bpt6k1090242p\"\\n  }\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-summary.txt', document_id='bpt6k1090242p', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k1090242p/bpt6k1090242p_prompt-summary.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date), while the `context` property contains information about the people and places that are most frequently mentioned in the play (such as label, mention frequency, and salient sentences where it appears).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": null,\\n    \"title\": \"Tite et Titus, ou Critique sur les Berenices, comédie\",\\n    \"publication_date\": \"1673\",\\n    \"document_id\": \"bpt6k1090242p\"\\n  },\\n  \"context\": {\\n    \"people\": {\\n      \"top_1_person\": {\\n        \"entity\": {\\n          \"label\": \"THALIE\",\\n          \"frequency\": 5\\n        },\\n        \"related_sentences\": [\\n          \"Oui sans doute, savante Nim hé, et si tous les entiments de Titus m\\'ont toujours servi de Loi, ors même que j\\'ai eu sujet de les trouver les lus injustes, il n\\'y a pas apparence que je le désaoue quand il m\\'en attribue d\\'aussi raisonnables que ceux -là. \\\\nTHALIE\\\\n J\\'ai bien de la joie, illustres Amants, de vous évoir dans un si bon accord, et tous ceux, que outre séparation avait si fort affligés, Jusques à les lire fondre en Larmes, seront bien consolez, and ils sauront votre bonne intelligence prêlen: vous vous étiez pourtant séparés avec assés de eremonie, et votre à dieu avait été asséz long, our tenir plus longtemps, et pour ne vous pas revIr si tôt.\",\\n          \"Il parait bien à vos discours, savante Nim que les grâces et les jeux ne vous abandonne mais, et l\\'obligeante raillerie, dont vous u accueillie, ne pouvait être assaisonnée pa main plus délicate aussi jo la reçois avec tos reconnaissance que méritent les civilités, et louanges d\\'une immortelle comme vous. \\\\nTHALIE\\\\n Vous venez à propos en ce pays, aimable l\\'ut cesse, et le sort vous y à sans doute conduite p\",\\n          \"En effet, ma sœur n\\'a pas raison de vous cette raillerie, mais il ne faut pas que cela vousfraie: épar, outre que tout céqu\\'elle dit n\\'est lesouvent que pour rire, élle est obligée de défe vos Ennemis ayant ordre d\\'Apollon de les pie ger, comme il m\\'a chargée de vous conduire TITUS à THALIE Aimable\",\\n          \", j\\'ai encore plus grand jet que Tite d\\'appréhender qu\\'on ne me prenne our une autre, et qu\\'on ne m\\'attribue bien des hoses, qui ne me conviennent pas. \\\\nTHALIE\\\\n C\\'en est assurés pour le présent, belle Princesse ous avés apparemament plus besoin de repos que de ascours;\",\\n          \"Thalie, il ne faut pas que cette inégalité vous surprenne, la différence que vous trouvez entre notre entretien et ceux que Titus vous à rappoitéz, est une suitte nécessaire de la différence des matières, il est bien aisé d\\'être clair dans un entretien familier comme celui cy ou l\\'on ne parle que\"\\n        ]\\n      },\\n      \"top_5_persons\": [\\n        \"THALIE\",\\n        \"Tite\",\\n        \"Titus\",\\n        \"Berenice\",\\n        \"Apollon\"\\n      ]\\n    },\\n    \"places\": {\\n      \"top_1_place\": {\\n        \"entity\": {\\n          \"label\": \"Parnasse\",\\n          \"frequency\": 5\\n        },\\n        \"related_sentences\": [\\n          \"Ces noms sont en vénération au Parnasse l\\'un a té le père du Théâtre Français et l\\'autre en est le burrislier, personne, ô Melpomene, ne le sait jeux que vous, mais passons outre, vous Tite mmancéz mais acte condition de ne dire précinent que ce qui sait contre Titus et ce que vous ouvez à redire en lui etde ne dire point ce qui fait pour vous et ce qu\\'on peut vous objecter etcela re.\",\\n          \"c\\'est ainsi que Paris est devenu aujourd\\'aui le lieu du monde ou nous sommes en plus grande estime et les plus connue, aussi voyez vous qu\\'Apollon et nous ne parlons tous que Français, c\\'est jamais présent la langue du Parnasse et toute autre y est arbare, telle est la vicissitude des choses, mais j\\'apperçois, Aposson qui s\\'avance et vous allez et ugéz.\",\\n          \"c\\'est pourquoi abstenéz vous en soigneusement, si vous êtes sagé, quand vous retournerez en France, il sera permis à vous de reprendre votre jargon, puisqu\\'il y a des gens qu\\'en accommodent, mais tant que vous seréseréz au Parnasse, vivez selon la loi du pays.\",\\n          \"Ur fin qu\\'il en soit mémoire ôrmaise et pour empêcher que pareille chose ne puisse arriver à l\\'avenir, l est enioint à tous ceux qui gardent les entrées du Parnasse, qu\\'ils aient désormais ne laisser plus montrer personne de quelque qualité et condition que ce soit;\",\\n          \"soyer d les biens venus Princes, il ne vous rêle pluss nous dire de qui sont vos lettres d\\'adresse qui vous a donné passe port pour monter sur le Parnasse MELPOMENE.\"\\n        ]\\n      },\\n      \"top_5_places\": [\\n        \"Parnasse\",\\n        \"Rome\",\\n        \"France\",\\n        \"Bervie\",\\n        \"Carthage\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-summary.txt', document_id='bpt6k852913n', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k852913n/bpt6k852913n_prompt-summary.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date), while the `context` property contains information about the people and places that are most frequently mentioned in the play (such as label, mention frequency, and salient sentences where it appears).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Néel\",\\n    \"title\": \"L\\'illusion grotesque ou le point nécromancien, comédie / par M. Néel...\",\\n    \"publication_date\": \"1678\",\\n    \"document_id\": \"bpt6k852913n\"\\n  },\\n  \"context\": {\\n    \"people\": {\\n      \"top_1_person\": {\\n        \"entity\": {\\n          \"label\": \"Ormin\",\\n          \"frequency\": 2\\n        },\\n        \"related_sentences\": [\\n          \"Mais puis qu\\'il faut agir, agissons de concert, Et montrons qu\\'a plopos ce enaugemient nous sert5 La ruse en est subtile, et tout ce qui m\\'étonne C\\'est que Philandre encor de rien ne vous soupçonne, Et que toute l\\'intrigue est conduite à ce point Qu\\'il se voit presque pris, et ne le connaît point, \\\\nORMIN\\\\n Mais sachez que Crispin, comme j\\'ai pu l\\'instruire, En faisant le Devin a bien su se conduire, Et que par là Philandre est fort embarrassé Autant sur son hymen, que sur le temps passé.\",\\n          \"Quels devoirs nuit et jour le peuple me vient rendre, Et pour m\\'avoir déplu, combien j\\'en ai fait pendre? \\\\nORMIN\\\\n J\\'en ai dit encor plus afin de l\\'engager, Que tous vos sentiments n\\'allaient qu\\'à l\\'obliger;\",\\n          \"Oui, cela se peut faire aussi tôt qu\\'un Commis? \\\\nPHILANDRE\\\\n je veux uile en prenant un habillement gris. \\\\nORMIN\\\\n Et quel nom prendrez-vous? \\\\nPHILANDRE\\\\n Ou quelque autre à ton choix.\",\\n          \"\\\\nORMIN\\\\n Vous apprendrez que mon Maître Philandre, Qui se veut marier, ma fait malgré moi prendre Cette hient parure ce cet haait d\\'honneur, Pour être de ses vœux l\\'unique ambassadeur.\",\\n          \"Parle moi nettement, je veux que l\\'on s\\'explique, \\\\nORMIN\\\\n Un Savetier, Monsieur, parlant avec honheur, M\\'ayant montré de loin où votre Devineur Avait accoutumé de faire résidence.\"\\n        ]\\n      },\\n      \"top_5_persons\": [\\n        \"Ormin\",\\n        \"ARMINDE\",\\n        \"CRISPIN\",\\n        \"Beatrix\",\\n        \"Roselle\"\\n      ]\\n    },\\n    \"places\": {\\n      \"top_1_place\": {\\n        \"entity\": {\\n          \"label\": \"Senlis\",\\n          \"frequency\": 2\\n        },\\n        \"related_sentences\": [\\n          \"Elle voudrait déjà bien me tenir. \\\\nMASCARILLE\\\\n De grâce, Tant plus je m\\'étudie aux traits de votre face, E j Et plus je vois l\\'objet que j\\'ai vu dans Senlis Ne lésait-ce point vous ? \\\\nPHILANDRE\\\\n Non, mais bien à Paris Dedans le Luxembourg, et même aux Tuilleries, Je m\\'y suis signalé par mille batteries;\",\\n          \"J\\'arrive de Senlis pour épouser la fille, Tel que vous me voyez, de Monfieur Mascarille\"\\n        ]\\n      },\\n      \"top_5_places\": [\\n        \"Senlis\",\\n        \"Chalons en Champagne\",\\n        \"Paris\",\\n        \"Luxembourg\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-metadata.txt', document_id='bpt6k852913n', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k852913n/bpt6k852913n_prompt-metadata.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Néel\",\\n    \"title\": \"L\\'illusion grotesque ou le point nécromancien, comédie / par M. Néel...\",\\n    \"publication_date\": \"1678\",\\n    \"document_id\": \"bpt6k852913n\"\\n  }\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-excerpt.txt', document_id='bpt6k852913n', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k852913n/bpt6k852913n_prompt-excerpt.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date), while the `excerpt` property contains an excerpt of 400 words sampled from around the middle of the document.\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Néel\",\\n    \"title\": \"L\\'illusion grotesque ou le point nécromancien, comédie / par M. Néel...\",\\n    \"publication_date\": \"1678\",\\n    \"document_id\": \"bpt6k852913n\"\\n  },\\n  \"excerpt\": \"i, le voici qui s\\'avance; Qu\\'on nous laisse ici seuls. Ç ij SCÈNE III. PHIDADRE, IALEMON. \\\\nPHILANDRE\\\\n MOnseur, la connaissancs Que vous donne votre Ait des choses t ienir, Me fait vous consulter pour vous entretenir D\\'un scrupule importun dont la fin m\\'embarrasse. POLEMON. Il n\\'est rien que pour vous volontiers je ne fasse; Vous n\\'avez qu\\'à parler, et me prescrire en quoi Votre esprit inquiet veut\"\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-summary.txt', document_id='bpt6k5772699f', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k5772699f/bpt6k5772699f_prompt-summary.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date), while the `context` property contains information about the people and places that are most frequently mentioned in the play (such as label, mention frequency, and salient sentences where it appears).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Charenton, De\",\\n    \"title\": \"La mort de Baltazar, roy de Babilone , tragédie. Par le sieur de Charenton\",\\n    \"publication_date\": \"1662\",\\n    \"document_id\": \"bpt6k5772699f\"\\n  },\\n  \"context\": {\\n    \"people\": {\\n      \"top_1_person\": {\\n        \"entity\": {\\n          \"label\": \"Nabal\",\\n          \"frequency\": 3\\n        },\\n        \"related_sentences\": [\\n          \"Que votre bruit encor répond à votre audace, Que vous savez vanter ce qui n\\'est point de vous, Que votre humeur vous rend insupportable à rous, Que vous abusez trop du pouvoir qu\\'on vous donne, Que vous méconnaissez le sang de ma personne, Qu\\'en sin votre arrogance est venut à ce point Qu\\'un cœur comme le mien ne la sousfrira point, Qu\\'il faut à vos dépens. \\\\nNABAL\\\\n Ah, c\\'est trop vous entharé.\",\\n          \"Nsin par un malheur qui n\\'eût jamais d\\'égal, LI’de pour partie un Roi, mon amour et Nabal, Je me vois attaqué dans cetre dissérence, Que l\\'amour court au cœur, et laisse l\\'espérance, L\\'amour se sert de feux pour attaquer le cœur, Nabal par son crédit lui de sa douleur, Le Roi d\\'autorité répond à sa tristesse, Tous trois diversement causent ce qui me blesse, Que derermineray-je avec ce déplaisir?\",\\n          \"Nabal est sans défauts, homme dont les exploits Ont porté son mérite à s\\'égaller aux Rois, Il a foret cent sois, cent rempara, cent murailles, Combattu comme un Mars aumilieu des batailles, Fait redouter mon nom au bruit de ses combats, De Province en Province étendu mes Étars, Il doit à ce mérite et non à sa naissance, Son éclat et son rang qu\\'il tient pour recompence.\",\\n          \"Mais charmante beauré dans mon rigoureux sort, Malgré tous mes respects, Seigneur dois zaïre un éfort: Nabal dans son dessein m\\'oblige à me contraindre, M\\'oblige à vous parler, m\\'oblige A ne plus feindre: Il tire de mon cœur le secret de mes feux, Et pour le prévenir tu vous osefre mes vœux: Le met en est lâché, ma Divine Princesse, Mon cœur s\\'est découvert\",\\n          \". LE ROY, NAFAI naba caibe écectant par l\\'ordre du Ro LE ROY, As-tutont enten du \\\\nNABAL\\\\n Seigneur c\\'est ma douleur, J\\'apprends de son refus jusqu\\'où va mon malheur: Votre amitié combat, mais sa sierté l\\'emporte, Contre votre puissance elle devient plus forte, Et loin d\\'appréhender votre juste courroux, Se condamne elle -même à tomber sous ses coups.\"\\n        ]\\n      },\\n      \"top_5_persons\": [\\n        \"Nabal\",\\n        \"MISIA\",\\n        \"BALTAZAR\",\\n        \"Cyrus\",\\n        \"Arbas\"\\n      ]\\n    },\\n    \"places\": {\\n      \"top_1_place\": {\\n        \"entity\": {\\n          \"label\": \"Paris\",\\n          \"frequency\": 3\\n        },\\n        \"related_sentences\": [\\n          \"ledit Livre sans le consentement dudit Sieur de Charenton, à peine aux contrevenants de six mille livr ès d\\'amende, consiscation des exemplaires, et de tous dépens, dommages et intérêts, ainsi il est plus amplement porté par Priuilege Et ledit Sieur de Charenton a cédé nuant droict de Privilège à Nicolas Peingué et Jean Guignard fils, Marhands Libraires à Paris, pour en ouïr pendant ledit temps, suivant accordiaic entrait Entraient.\",\\n          \"Tout Paris admire que vous ne demeurez astachaît?  is Monde, que pour en être plus près, et pour lui communiquer vos assistances.\",\\n          \"grâce et Privilège du Roi donné à Paris\"\\n        ]\\n      },\\n      \"top_5_places\": [\\n        \"Paris\",\\n        \"PARIS\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-metadata.txt', document_id='bpt6k5772699f', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k5772699f/bpt6k5772699f_prompt-metadata.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Charenton, De\",\\n    \"title\": \"La mort de Baltazar, roy de Babilone , tragédie. Par le sieur de Charenton\",\\n    \"publication_date\": \"1662\",\\n    \"document_id\": \"bpt6k5772699f\"\\n  }\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-excerpt.txt', document_id='bpt6k5772699f', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k5772699f/bpt6k5772699f_prompt-excerpt.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date), while the `excerpt` property contains an excerpt of 400 words sampled from around the middle of the document.\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Charenton, De\",\\n    \"title\": \"La mort de Baltazar, roy de Babilone , tragédie. Par le sieur de Charenton\",\\n    \"publication_date\": \"1662\",\\n    \"document_id\": \"bpt6k5772699f\"\\n  },\\n  \"excerpt\": \"onge vous étonne, Une vapeur de nuit ne peut nuire à personne: Bannissez, bannissez cette vaine terreur, Qui cause votre crainte, et vous abat le cœur. Quel danger courons-nous dedans nos sorteresses? Lln dou A daus Celui d\\'être surpris pendant nos allégresses LE ROY. Quoi vous craignez Cyrus dans l\\'heure du festin? À l\\'abri de nos murs Seigneur brave le destin: Il faut pour gagner l\\'antre, il fau\"\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-summary.txt', document_id='bpt6k9807756q', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k9807756q/bpt6k9807756q_prompt-summary.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date), while the `context` property contains information about the people and places that are most frequently mentioned in the play (such as label, mention frequency, and salient sentences where it appears).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Genest, Charles-Claude\",\\n    \"title\": \"Zelonide, princesse de Sparte . Tragedie\",\\n    \"publication_date\": \"1682\",\\n    \"document_id\": \"bpt6k9807756q\"\\n  },\\n  \"context\": {\\n    \"people\": {\\n      \"top_1_person\": {\\n        \"entity\": {\\n          \"label\": \"Pyrrhus\",\\n          \"frequency\": 52\\n        },\\n        \"related_sentences\": [\\n          \"Mais cette jeune ardeur qui vous porte aux combats, Seigneur, aurait besoin d\\'armes et de Soldats Malgré ces hauts désirs notre Ville déserte Sans pouvoir se défendre à Pyrrhus est ouverte.\",\\n          \"Il va chercher Pyrrhus, en implorer l\\'appui, J\\'y consens, je le porte à traiter avec lui, Il réussit.\",\\n          \"Aux Armes de Pyrrhus sans défense livrée, Sa honte est infaillible, ou sa perte assurée.\",\\n          \"Quand Pyrrhus nous ferait succomber, Tout l\\'État avec nous n\\'est pas prêt à tomber.\",\\n          \"si le fier Pyrrhus ose nous outrager, Ne délibérons point, et courons nous venger;\"\\n        ]\\n      },\\n      \"top_5_persons\": [\\n        \"Pyrrhus\",\\n        \"Pyrrhus\",\\n        \"Pyrrhus\",\\n        \"Phillus\",\\n        \"Spartiates\"\\n      ]\\n    },\\n    \"places\": {\\n      \"top_1_place\": {\\n        \"entity\": {\\n          \"label\": \"Sparte\",\\n          \"frequency\": 52\\n        },\\n        \"related_sentences\": [\\n          \"D\\'autres ont prétendu disputer à Zélonide le titre de parfaite Héroïne Outre que la perfection absolue n\\'est pas toujours nécessaire aux Héros de la Tragédie, j\\'ai à répondre encore qu\\'on ne sait pas bien toutes les circonstances de la rupture de Zélonide avec Cléonime, et de son engagement avec Acorate mais que toutes les langes qu\\'on lui donne à Sparte, et les aclamations que font pour elle tant de Sages Vieillards, montrent assez qu\\'ils la regardaient comme une Princesse Héroïque:\",\\n          \"Mais ce qui était inconnu à Sparte, et en quoi vous l\\'emportez sans doute sur Elles, c\\'est d\\'avoir toute la grandeur et toute l\\'élévation de leurs sentiments, sans rien perdre de cette charmante douceur, et de cette délicate bienséance qui sont si propres à nêtre Sexe, et qui sont le dernier trait, et l\\'accomplissement des Grâces et des Vertus.\",\\n          \"Que Sparte toujours libre, et toujours souveraine, Pouponhonreloi ne tut pon raccepter, Et pour son Ennemi ne peut le redouter. \\\\nLISIMACUS\\\\n Vous quitterez bien tôt cet orguëil téméraire, Quand vous verrez sur vous éclater la colère D\\'un Roi que sa clémence a voulu retenir, Et tel qu\\'un Dieu vengeur forcé de vous punir. \\\\nACORATE\\\\n \",\\n          \"Mon Père et nos Guerriers qu\\'à luivis la victoire, Reviendront venger Sparte, et rétablir sa gloire, Ou se feront enfin un Thrône et des Remparts, Par Part où s\\'étendra la pointe de leurs dards. \\\\nPHILUS\\\\n Que nos Enfants il eners, nos illustres Spartaines Évitent promtement et la mort et les chaînes.\",\\n          \"C\\'est pour la proposer que vient Lisimacus Il tient le premier rang à la Cour de Pirrhus Songez en était parlant au pouvoir de son maître, Songez qu\\'un Camp nombreux dans nos champs va paraître, Que Sparte aux Ennemis s\\'ouvre de toutes parts, Vuide des Habitants qui sont ses seuls Remparts.\"\\n        ]\\n      },\\n      \"top_5_places\": [\\n        \"Sparte\",\\n        \"Grèce\",\\n        \"France\",\\n        \"Paris\",\\n        \"Rome\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-metadata.txt', document_id='bpt6k9807756q', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k9807756q/bpt6k9807756q_prompt-metadata.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date).\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Genest, Charles-Claude\",\\n    \"title\": \"Zelonide, princesse de Sparte . Tragedie\",\\n    \"publication_date\": \"1682\",\\n    \"document_id\": \"bpt6k9807756q\"\\n  }\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```'),\n",
       " LLMrequest(prompt_id='prompt-excerpt.txt', document_id='bpt6k9807756q', prompt_path=PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/prompts/pregenerated/bpt6k9807756q/bpt6k9807756q_prompt-excerpt.txt'), prompt='Look at the following JSON object describing a theatre play in French (XVII century); the `metadata` property contains basic information about the play (author, title, publication date), while the `excerpt` property contains an excerpt of 400 words sampled from around the middle of the document.\\n\\nINPUT:\\n```json\\n{\\n  \"metadata\": {\\n    \"author\": \"Genest, Charles-Claude\",\\n    \"title\": \"Zelonide, princesse de Sparte . Tragedie\",\\n    \"publication_date\": \"1682\",\\n    \"document_id\": \"bpt6k9807756q\"\\n  },\\n  \"excerpt\": \"mmes animées, A de plus beaux desseins Sparte nous a formées. Loin de vous retenir par des charmes trompeurs, Sans cesse aux grands exploits nous enflammons vos cœurs. Nous voulons que l\\'amour les embrase et les guide Pour prendre vers la gloire un essor plus rapide. Quelle outrageuse erreur vous fait donc présumer Qu\\'ici nous vous nuirons, loin de vous animer? Aider à soutenir un Thrône qui chanc\"\\n}\\n```\\n\\nYour role is to predict the location and historical period in which the action of the play is set. \\n\\nKEY RULES:\\n- Predict the timespan and not the precise and exact date of the period where the play could have taken place\\n- Do not write an introduction or summary \\n- The response must contain only valid JSON\\n- The values in the JSON \"timeframe_start\" and \"timeframe_end\" should always be a single valid date in the form [±Y]YYYY; negative values should be used for years before common era B.C.E. (e.g. `300 B.C.` should be represented as `-300`)\\n- if the provided information is not sufficient to determine historical period and/or location, the following values can be set to `None`: `period`, `timeframe_start`, `timeframe_end`, `location`, `location_qid`\\n\\nReturn your response and the underlying reasoning as a JSON object with the following structure:\\n```json\\n{\\n    \"period\": \"The historical period in which the play could have taken place\",\\n    \"period_reasoning\": \"The reasoning the model used to identify the historical period\",\\n    \"timeframe_start\": \"The start value of the historical period, formatted as [±Y]YYYY\",\\n    \"timeframe_end\": \"The end value of the historical period, formatted as [±Y]YYYY\",\\n    \"location\": \"The geographic location where the action of the play takes place\",\\n    \"location_reasoning\": \"The reasoning the model used to identify the geographic location\",\\n    \"location_qid\": \"The Wikidata QID of the identified location\"\\n}\\n```')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/validation/llm_responses')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_llm_responses_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the LLM responses before generating new ones \n",
    "def clean_up_directory(directory_path: Path) -> None:\n",
    "    for item in directory_path.iterdir():\n",
    "        if item.is_dir():\n",
    "            print(f'Removed folder {item} and all its contents')\n",
    "            shutil.rmtree(item)\n",
    "        else:\n",
    "            print(f'Removed file {item}')\n",
    "            item.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_up_directory(validation_llm_responses_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ai.Client()\n",
    "client.configure({\"ollama\" : {\"timeout\": 600}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ollama:phi4-mini:latest',\n",
       " 'ollama:gemma3:12b',\n",
       " 'ollama:mistral-small:24b',\n",
       " 'ollama:deepseek-r1:14b',\n",
       " 'ollama:deepseek-r1:32b',\n",
       " 'openai:o1-mini',\n",
       " 'openai:gpt-4o',\n",
       " 'deepseek:deepseek-reasoner',\n",
       " 'anthropic:claude-3-7-sonnet-20250219']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ollama:phi4-mini:latest\n",
      "Skipping ollama:gemma3:12b\n",
      "Skipping ollama:mistral-small:24b\n",
      "Skipping ollama:deepseek-r1:14b\n",
      "Skipping ollama:deepseek-r1:32b\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k10901623 using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 7.35 seconds. Total tokens: 1427\n",
      "Processing prompt prompt-metadata.txt for document bpt6k10901623 using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 7.43 seconds. Total tokens: 1278\n",
      "Processing prompt prompt-summary.txt for document bpt6k10901623 using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 7.94 seconds. Total tokens: 2290\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k1090242p using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 9.95 seconds. Total tokens: 2094\n",
      "Processing prompt prompt-metadata.txt for document bpt6k1090242p using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 9.10 seconds. Total tokens: 1236\n",
      "Processing prompt prompt-summary.txt for document bpt6k1090242p using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 9.44 seconds. Total tokens: 2942\n",
      "Processing prompt prompt-summary.txt for document bpt6k852913n using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 5.72 seconds. Total tokens: 2133\n",
      "Processing prompt prompt-metadata.txt for document bpt6k852913n using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 4.33 seconds. Total tokens: 1089\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k852913n using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 5.62 seconds. Total tokens: 1570\n",
      "Processing prompt prompt-summary.txt for document bpt6k5772699f using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 5.51 seconds. Total tokens: 2134\n",
      "Processing prompt prompt-metadata.txt for document bpt6k5772699f using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 6.16 seconds. Total tokens: 1082\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k5772699f using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 8.04 seconds. Total tokens: 1115\n",
      "Processing prompt prompt-summary.txt for document bpt6k9807756q using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 5.39 seconds. Total tokens: 2011\n",
      "Processing prompt prompt-metadata.txt for document bpt6k9807756q using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 6.17 seconds. Total tokens: 1300\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k9807756q using model openai:o1-mini (temp=None)\n",
      "Time taken to get response: 6.66 seconds. Total tokens: 1547\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k10901623 using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 3.70 seconds. Total tokens: 725\n",
      "Processing prompt prompt-metadata.txt for document bpt6k10901623 using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 3.53 seconds. Total tokens: 616\n",
      "Processing prompt prompt-summary.txt for document bpt6k10901623 using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 2.80 seconds. Total tokens: 1263\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k1090242p using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 5.06 seconds. Total tokens: 753\n",
      "Processing prompt prompt-metadata.txt for document bpt6k1090242p using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 4.67 seconds. Total tokens: 610\n",
      "Processing prompt prompt-summary.txt for document bpt6k1090242p using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 3.27 seconds. Total tokens: 1714\n",
      "Processing prompt prompt-summary.txt for document bpt6k852913n using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 4.36 seconds. Total tokens: 1312\n",
      "Processing prompt prompt-metadata.txt for document bpt6k852913n using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 3.10 seconds. Total tokens: 607\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k852913n using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 4.25 seconds. Total tokens: 755\n",
      "Processing prompt prompt-summary.txt for document bpt6k5772699f using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 3.60 seconds. Total tokens: 1504\n",
      "Processing prompt prompt-metadata.txt for document bpt6k5772699f using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 3.12 seconds. Total tokens: 607\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k5772699f using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 4.00 seconds. Total tokens: 772\n",
      "Processing prompt prompt-summary.txt for document bpt6k9807756q using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 3.27 seconds. Total tokens: 1467\n",
      "Processing prompt prompt-metadata.txt for document bpt6k9807756q using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 6.75 seconds. Total tokens: 597\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k9807756q using model openai:gpt-4o (temp=0.2)\n",
      "Time taken to get response: 2.84 seconds. Total tokens: 703\n",
      "Skipping request for document bpt6k10901623[prompt-excerpt.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k10901623[prompt-metadata.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k10901623[prompt-summary.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k1090242p[prompt-excerpt.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k1090242p[prompt-metadata.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k1090242p[prompt-summary.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k852913n[prompt-summary.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k852913n[prompt-metadata.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k852913n[prompt-excerpt.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k5772699f[prompt-summary.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k5772699f[prompt-metadata.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k5772699f[prompt-excerpt.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k9807756q[prompt-summary.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k9807756q[prompt-metadata.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k9807756q[prompt-excerpt.txt] using model deepseek:deepseek-reasoner as it already exists\n",
      "Skipping request for document bpt6k10901623[prompt-excerpt.txt] using model anthropic:claude-3-7-sonnet-20250219 as it already exists\n",
      "Skipping request for document bpt6k10901623[prompt-metadata.txt] using model anthropic:claude-3-7-sonnet-20250219 as it already exists\n",
      "Skipping request for document bpt6k10901623[prompt-summary.txt] using model anthropic:claude-3-7-sonnet-20250219 as it already exists\n",
      "Skipping request for document bpt6k1090242p[prompt-excerpt.txt] using model anthropic:claude-3-7-sonnet-20250219 as it already exists\n",
      "Skipping request for document bpt6k1090242p[prompt-metadata.txt] using model anthropic:claude-3-7-sonnet-20250219 as it already exists\n",
      "Skipping request for document bpt6k1090242p[prompt-summary.txt] using model anthropic:claude-3-7-sonnet-20250219 as it already exists\n",
      "Skipping request for document bpt6k852913n[prompt-summary.txt] using model anthropic:claude-3-7-sonnet-20250219 as it already exists\n",
      "Skipping request for document bpt6k852913n[prompt-metadata.txt] using model anthropic:claude-3-7-sonnet-20250219 as it already exists\n",
      "Skipping request for document bpt6k852913n[prompt-excerpt.txt] using model anthropic:claude-3-7-sonnet-20250219 as it already exists\n",
      "Processing prompt prompt-summary.txt for document bpt6k5772699f using model anthropic:claude-3-7-sonnet-20250219 (temp=None)\n",
      "Time taken to get response: 5.35 seconds. Total tokens: 1896\n",
      "Processing prompt prompt-metadata.txt for document bpt6k5772699f using model anthropic:claude-3-7-sonnet-20250219 (temp=None)\n",
      "Time taken to get response: 4.05 seconds. Total tokens: 720\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k5772699f using model anthropic:claude-3-7-sonnet-20250219 (temp=None)\n",
      "Time taken to get response: 5.96 seconds. Total tokens: 970\n",
      "Processing prompt prompt-summary.txt for document bpt6k9807756q using model anthropic:claude-3-7-sonnet-20250219 (temp=None)\n",
      "Time taken to get response: 6.20 seconds. Total tokens: 1870\n",
      "Processing prompt prompt-metadata.txt for document bpt6k9807756q using model anthropic:claude-3-7-sonnet-20250219 (temp=None)\n",
      "Time taken to get response: 4.56 seconds. Total tokens: 723\n",
      "Processing prompt prompt-excerpt.txt for document bpt6k9807756q using model anthropic:claude-3-7-sonnet-20250219 (temp=None)\n",
      "Time taken to get response: 4.22 seconds. Total tokens: 869\n"
     ]
    }
   ],
   "source": [
    "llm_responses = []\n",
    "reasoning_llms = ['openai:o1-mini', 'deepseek:deepseek-reasoner', 'anthropic:claude-3-7-sonnet-20250219']\n",
    "default_temperature = config['validation']['temperature']\n",
    "\n",
    "for model in llms:\n",
    "    if model.startswith('ollama'):\n",
    "        print(f'Skipping {model}')\n",
    "        continue\n",
    "    if model in reasoning_llms:\n",
    "        llm_responses += query_llm(client, model, llm_requests, validation_llm_responses_path)\n",
    "    else:\n",
    "        llm_responses += query_llm(client, model, llm_requests, validation_llm_responses_path, temperature=default_temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask LLM-judge\n",
    "\n",
    "- get list of LLM judges (from config file)\n",
    "- for each model, get score predictions and save to a dataframe/csv file (`data/validation/scores`)\n",
    "    - save both the predictions (scores + reasons) and the unpacked scores (for further processing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_llm_responses_path = Path(base_path / config['validation']['responses_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"['Unnamed: 11', 'Unnamed: 12'] not found in axis\"\n"
     ]
    }
   ],
   "source": [
    "# this should return only the test (validation) set (n=5 docs)\n",
    "validation_docs, df_validation_data = prepare_evaluation_dataframe(\n",
    "    llm_response_path=validation_llm_responses_path,\n",
    "    gt_annotations_path=gt_path,\n",
    "    gt_metadata_path=gt_path,\n",
    "    split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>document_id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>document_length</th>\n",
       "      <th>keep_fine_tuning</th>\n",
       "      <th>gt_period</th>\n",
       "      <th>pred_period</th>\n",
       "      <th>...</th>\n",
       "      <th>gt_preferred_location</th>\n",
       "      <th>gt_accepted_locations</th>\n",
       "      <th>pred_location</th>\n",
       "      <th>score_location_string</th>\n",
       "      <th>gt_preferred_location_QID</th>\n",
       "      <th>gt_acceptable_location_QIDs</th>\n",
       "      <th>pred_location_qid</th>\n",
       "      <th>score_location_qid</th>\n",
       "      <th>gt_location_reason</th>\n",
       "      <th>pred_location_reasoning</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-excerpt.txt$ollama:mistral-small:24b</th>\n",
       "      <td>prompt-excerpt.txt</td>\n",
       "      <td>ollama:mistral-small:24b</td>\n",
       "      <td>bpt6k10901623</td>\n",
       "      <td>Boisrobert, François de</td>\n",
       "      <td>Théodore, Reyne de Hongrie, tragi-comédie</td>\n",
       "      <td>1658</td>\n",
       "      <td>80779</td>\n",
       "      <td>True</td>\n",
       "      <td>Middle Ages</td>\n",
       "      <td>Middle Ages</td>\n",
       "      <td>...</td>\n",
       "      <td>Székesfehérvár</td>\n",
       "      <td>Székesfehérvár | Albe royale | Alba Regia | Hu...</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>None</td>\n",
       "      <td>Q130212</td>\n",
       "      <td>Q130212 | Q28</td>\n",
       "      <td>Q27</td>\n",
       "      <td>None</td>\n",
       "      <td>- name of the town: Albe royale - King and que...</td>\n",
       "      <td>The title explicitly mentions 'Hongrie', which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-summary.txt$openai:o1-mini</th>\n",
       "      <td>prompt-summary.txt</td>\n",
       "      <td>openai:o1-mini</td>\n",
       "      <td>bpt6k10901623</td>\n",
       "      <td>Boisrobert, François de</td>\n",
       "      <td>Théodore, Reyne de Hongrie, tragi-comédie</td>\n",
       "      <td>1658</td>\n",
       "      <td>80779</td>\n",
       "      <td>True</td>\n",
       "      <td>Middle Ages</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>Székesfehérvár</td>\n",
       "      <td>Székesfehérvár | Albe royale | Alba Regia | Hu...</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>None</td>\n",
       "      <td>Q130212</td>\n",
       "      <td>Q130212 | Q28</td>\n",
       "      <td>Q28</td>\n",
       "      <td>None</td>\n",
       "      <td>- name of the town: Albe royale - King and que...</td>\n",
       "      <td>The title of the play refers to 'Reyne de Hong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-metadata.txt$openai:gpt-4o</th>\n",
       "      <td>prompt-metadata.txt</td>\n",
       "      <td>openai:gpt-4o</td>\n",
       "      <td>bpt6k10901623</td>\n",
       "      <td>Boisrobert, François de</td>\n",
       "      <td>Théodore, Reyne de Hongrie, tragi-comédie</td>\n",
       "      <td>1658</td>\n",
       "      <td>80779</td>\n",
       "      <td>True</td>\n",
       "      <td>Middle Ages</td>\n",
       "      <td>Middle Ages</td>\n",
       "      <td>...</td>\n",
       "      <td>Székesfehérvár</td>\n",
       "      <td>Székesfehérvár | Albe royale | Alba Regia | Hu...</td>\n",
       "      <td>Kingdom of Hungary</td>\n",
       "      <td>None</td>\n",
       "      <td>Q130212</td>\n",
       "      <td>Q130212 | Q28</td>\n",
       "      <td>Q28</td>\n",
       "      <td>None</td>\n",
       "      <td>- name of the town: Albe royale - King and que...</td>\n",
       "      <td>The title explicitly mentions 'Reyne de Hongri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              prompt_id  \\\n",
       "response_id                                                               \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...   prompt-excerpt.txt   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini      prompt-summary.txt   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o     prompt-metadata.txt   \n",
       "\n",
       "                                                                  model_name  \\\n",
       "response_id                                                                    \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...  ollama:mistral-small:24b   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini               openai:o1-mini   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o                openai:gpt-4o   \n",
       "\n",
       "                                                      document_id  \\\n",
       "response_id                                                         \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...  bpt6k10901623   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini     bpt6k10901623   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o     bpt6k10901623   \n",
       "\n",
       "                                                                     author  \\\n",
       "response_id                                                                   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...  Boisrobert, François de   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini     Boisrobert, François de   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o     Boisrobert, François de   \n",
       "\n",
       "                                                                                        title  \\\n",
       "response_id                                                                                     \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...  Théodore, Reyne de Hongrie, tragi-comédie   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini     Théodore, Reyne de Hongrie, tragi-comédie   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o     Théodore, Reyne de Hongrie, tragi-comédie   \n",
       "\n",
       "                                                    publication_date  \\\n",
       "response_id                                                            \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...              1658   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini                 1658   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o                 1658   \n",
       "\n",
       "                                                    document_length  \\\n",
       "response_id                                                           \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...            80779   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini               80779   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o               80779   \n",
       "\n",
       "                                                    keep_fine_tuning  \\\n",
       "response_id                                                            \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...              True   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini                 True   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o                 True   \n",
       "\n",
       "                                                      gt_period  pred_period  \\\n",
       "response_id                                                                    \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...  Middle Ages  Middle Ages   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini     Middle Ages         None   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o     Middle Ages  Middle Ages   \n",
       "\n",
       "                                                    ... gt_preferred_location  \\\n",
       "response_id                                         ...                         \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...  ...        Székesfehérvár   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini     ...        Székesfehérvár   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o     ...        Székesfehérvár   \n",
       "\n",
       "                                                                                gt_accepted_locations  \\\n",
       "response_id                                                                                             \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...  Székesfehérvár | Albe royale | Alba Regia | Hu...   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini     Székesfehérvár | Albe royale | Alba Regia | Hu...   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o     Székesfehérvár | Albe royale | Alba Regia | Hu...   \n",
       "\n",
       "                                                         pred_location  \\\n",
       "response_id                                                              \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...             Hungary   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini                Hungary   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o     Kingdom of Hungary   \n",
       "\n",
       "                                                   score_location_string  \\\n",
       "response_id                                                                \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...                  None   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini                     None   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o                     None   \n",
       "\n",
       "                                                   gt_preferred_location_QID  \\\n",
       "response_id                                                                    \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...                   Q130212   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini                      Q130212   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o                      Q130212   \n",
       "\n",
       "                                                   gt_acceptable_location_QIDs  \\\n",
       "response_id                                                                      \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...               Q130212 | Q28   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini                  Q130212 | Q28   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o                  Q130212 | Q28   \n",
       "\n",
       "                                                   pred_location_qid  \\\n",
       "response_id                                                            \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...               Q27   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini                  Q28   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o                  Q28   \n",
       "\n",
       "                                                   score_location_qid  \\\n",
       "response_id                                                             \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...               None   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini                  None   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o                  None   \n",
       "\n",
       "                                                                                   gt_location_reason  \\\n",
       "response_id                                                                                             \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...  - name of the town: Albe royale - King and que...   \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini     - name of the town: Albe royale - King and que...   \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o     - name of the town: Albe royale - King and que...   \n",
       "\n",
       "                                                                              pred_location_reasoning  \n",
       "response_id                                                                                            \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:mistral...  The title explicitly mentions 'Hongrie', which...  \n",
       "bpt6k10901623$prompt-summary.txt$openai:o1-mini     The title of the play refers to 'Reyne de Hong...  \n",
       "bpt6k10901623$prompt-metadata.txt$openai:gpt-4o     The title explicitly mentions 'Reyne de Hongri...  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from textentlib.prompting import build_llm_judge_prompt\n",
    "\n",
    "def add_prompt(row) -> str:\n",
    "    \"\"\"\n",
    "    Builds a prompt for the LLM judge task based on the row data.\n",
    "    \"\"\"\n",
    "\n",
    "    prediction_columns = [col for col in df_validation_data.columns if col.startswith('pred_') and not col.endswith('reasoning')]\n",
    "    reference_columns = [col for col in df_validation_data.columns if col.startswith('gt_') and not col.endswith('reason')]\n",
    "\n",
    "    prediction_dict = row[prediction_columns].to_dict()\n",
    "    reference_dict = row[reference_columns].to_dict()\n",
    "\n",
    "    #print(reference_dict, prediction_dict)\n",
    "\n",
    "    prompt = build_llm_judge_prompt(\n",
    "        prediction=prediction_dict,\n",
    "        reference=reference_dict,\n",
    "        prompts_base_path=Path('../data/prompts/'))\n",
    "    return prompt\n",
    "\n",
    "def process_llm_judge_responses(llm_judge_responses) -> List[dict]:\n",
    "    scores  = []\n",
    "    for r in llm_judge_responses:\n",
    "        _, scores_dict = try_extract_json_from_text(r.response)\n",
    "        scores_dict['response_id'] = r.document_id\n",
    "        scores_dict['evaluator'] = r.model_name\n",
    "        scores_dict['total_tokens'] = r.total_tokens\n",
    "        scores.append(scores_dict)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation_data['llm_judge_prompt'] = df_validation_data.apply(add_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textentlib.llm_utils import LLMrequest, query_llm_judge, try_extract_json_from_text\n",
    "\n",
    "llm_judge_requests =[\n",
    "    LLMrequest(\n",
    "        prompt_id='llm_judge_prompt',\n",
    "        document_id=response_id,\n",
    "        prompt_path=None,\n",
    "        prompt=item['llm_judge_prompt']\n",
    "    )\n",
    "    for response_id, item in df_validation_data[['llm_judge_prompt']].to_dict(orient='index').items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llm_judge_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ai.Client()\n",
    "client.configure({\n",
    "  \"ollama\" : {\n",
    "    \"timeout\": 600,\n",
    "  }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_judges = config['llm-judge']['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ollama:phi4-mini:latest',\n",
       " 'ollama:mistral-small:24b',\n",
       " 'openai:o1-mini',\n",
       " 'deepseek:deepseek-reasoner',\n",
       " 'anthropic:claude-3-7-sonnet-20250219']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ollama:phi4-mini:latest\n",
      "Skipping ollama:mistral-small:24b\n",
      "Skipping openai:o1-mini\n",
      "Running predictions for model: deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$ollama:gemma3:12b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$openai:gpt-4o using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$anthropic:claude-3-7-sonnet-20250219 using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$ollama:deepseek-r1:14b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$ollama:deepseek-r1:32b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$openai:o1-mini using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$ollama:mistral-small:24b using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$deepseek:deepseek-reasoner using model deepseek:deepseek-reasoner\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$ollama:phi4-mini:latest using model deepseek:deepseek-reasoner\n",
      "Running predictions for model: anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-metadata.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-excerpt.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k10901623$prompt-summary.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-excerpt.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-summary.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k1090242p$prompt-metadata.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-metadata.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-excerpt.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k852913n$prompt-summary.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-summary.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-excerpt.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k5772699f$prompt-metadata.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$ollama:gemma3:12b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-metadata.txt$openai:gpt-4o using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$anthropic:claude-3-7-sonnet-20250219 using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$ollama:deepseek-r1:14b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$ollama:deepseek-r1:32b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$openai:o1-mini using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$ollama:mistral-small:24b using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-excerpt.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$deepseek:deepseek-reasoner using model anthropic:claude-3-7-sonnet-20250219\n",
      "Processing prompt llm_judge_prompt for document bpt6k9807756q$prompt-summary.txt$ollama:phi4-mini:latest using model anthropic:claude-3-7-sonnet-20250219\n"
     ]
    }
   ],
   "source": [
    "# Query LLMs and collect responses\n",
    "reasoning_llms = ['openai:o1-mini', 'deepseek:deepseek-reasoner', 'anthropic:claude-3-7-sonnet-20250219']\n",
    "default_temperature = config['llm-judge']['temperature']\n",
    "scores_output_path = Path(config['llm-judge']['scores_output_path'])\n",
    "\n",
    "for model in llm_judges:\n",
    "    # ask only LLMs with an API\n",
    "    if model.startswith('ollama') or model == \"openai:o1-mini\":\n",
    "        print(f'Skipping {model}')\n",
    "        continue\n",
    "\n",
    "    # Query the candidate judge LLMs\n",
    "    llm_judge_responses = []\n",
    "    print('Running predictions for model:', model)\n",
    "    if model in reasoning_llms:\n",
    "        llm_judge_responses += query_llm_judge(client, model, llm_judge_requests)\n",
    "    else:\n",
    "        llm_judge_responses += query_llm_judge(client, model, llm_judge_requests, temperature=default_temperature)\n",
    "    \n",
    "    # Stores produced socres in a TSV file\n",
    "    scores  = process_llm_judge_responses(llm_judge_responses)\n",
    "    scores_tsv_path = base_path / scores_output_path / f\"{model}_scores.tsv\"\n",
    "    pd.DataFrame(scores).to_csv(f\"{scores_tsv_path}\", sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute IAA between scorers\n",
    "\n",
    "- read in all the scores on the validation docs (human + LLM-judge)\n",
    "- reshape dataframe so to have for each document and for each score type, all the scores assigned\n",
    "- for each score type compute the IAA\n",
    "- compute an average IAA across all score types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def prepare_scores_dataframe(scores_csv_file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares a dataframe from the LLM judge's scores CSV file.\n",
    "    \"\"\"\n",
    "    df_scores = pd.read_csv(scores_csv_file_path, sep='\\t')\n",
    "\n",
    "    # isolatehe the columns that contain scores\n",
    "    # and remove the ones that contain LLM's reasons for scoring\n",
    "    score_columns = [\n",
    "        col\n",
    "        for col in df_scores.columns\n",
    "        if col.startswith('score_') and not 'reasons' in col\n",
    "    ]\n",
    "\n",
    "    # reshape the dataframe to have one score per row\n",
    "    unpacked_scores = []\n",
    "    for row_id, row in df_scores.iterrows():\n",
    "        for score_column in score_columns:\n",
    "            score_value = row[score_column]\n",
    "            score_name = score_column\n",
    "            unpacked_scores.append({\n",
    "                'response_id': row.response_id,\n",
    "                'score_name': score_name,\n",
    "                'score_value': score_value,\n",
    "                'evaluator': row.evaluator\n",
    "            })\n",
    "    df = pd.DataFrame(unpacked_scores)\n",
    "    return pd.pivot_table(\n",
    "        df,\n",
    "        index=['response_id', 'score_name'],\n",
    "        columns='evaluator',\n",
    "        values='score_value'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_human_scores_dataframe(scores_csv_file_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepares a dataframe from the human annotator's scores CSV file.\n",
    "    \"\"\"\n",
    "    df_scores = pd.read_csv(scores_csv_file_path, sep='\\t')\n",
    "\n",
    "    evaluator_name = scores_csv_file_path.stem.split('_')[0]\n",
    "\n",
    "    # isolatehe the columns that contain scores\n",
    "    # and remove the ones that contain LLM's reasons for scoring\n",
    "    score_columns = [\n",
    "        col\n",
    "        for col in df_scores.columns\n",
    "        if col.endswith('_score') and not 'reasons' in col\n",
    "    ]\n",
    "\n",
    "    value_replacements = {\n",
    "        'location_qid_score' : 'score_location_qid',\n",
    "        'location_string_score' : 'score_location_string',\n",
    "        'period_string_score' : 'score_period_string',\n",
    "        'period_timeframe_score' : 'score_period_interval',\n",
    "    }\n",
    "\n",
    "    # reshape the dataframe to have one score per row\n",
    "    unpacked_scores = []\n",
    "    for row_id, row in df_scores.iterrows():\n",
    "        for score_column in score_columns:\n",
    "            score_value = row[score_column]\n",
    "            score_name = score_column\n",
    "            unpacked_scores.append({\n",
    "                'response_id': row.response_id,\n",
    "                'score_name': value_replacements[score_name],\n",
    "                'score_value': score_value,\n",
    "                'evaluator': evaluator_name\n",
    "            })\n",
    "    df = pd.DataFrame(unpacked_scores)\n",
    "    return pd.pivot_table(\n",
    "        df,\n",
    "        index=['response_id', 'score_name'],\n",
    "        columns='evaluator',\n",
    "        values='score_value'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = config['llm-judge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_judge_scores_path = Path(base_path / settings['scores_output_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing deepseek:deepseek-reasoner\n",
      "Processing anthropic:claude-3-7-sonnet-20250219\n",
      "Processing ollama:mistral-small:24b\n",
      "Processing openai:o1-mini\n",
      "Processing ollama:phi4-mini:latest\n",
      "Error processing /Users/mromanel/Documents/UniGe-TextEnt/chrono-spatial-processing/data/validation/llm_judge_scores/ollama:phi4-mini:latest_scores.tsv: agg function failed [how->mean,dtype->object]\n",
      "Processing ollama:gemma3:12b\n"
     ]
    }
   ],
   "source": [
    "for csv_file in llm_judge_scores_path.glob('*.tsv'):\n",
    "    model_name = csv_file.name.split('_')[0]\n",
    "    print(f\"Processing {model_name}\")\n",
    "    try:\n",
    "        scores[model_name] = prepare_scores_dataframe(csv_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {csv_file}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "scores_dataframes = list(scores.values())\n",
    "df_llmjudges_scores = reduce(lambda left, right: pd.merge(left, right, on=['response_id', 'score_name'], how='outer'), scores_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluator</th>\n",
       "      <th>deepseek:deepseek-reasoner</th>\n",
       "      <th>anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <th>ollama:mistral-small:24b</th>\n",
       "      <th>openai:o1-mini</th>\n",
       "      <th>ollama:gemma3:12b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response_id</th>\n",
       "      <th>score_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">bpt6k10901623$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <th>score_location_qid</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_location_string</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_period_interval</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_period_string</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">bpt6k10901623$prompt-excerpt.txt$deepseek:deepseek-reasoner</th>\n",
       "      <th>score_location_qid</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_location_string</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_period_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_period_string</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">bpt6k10901623$prompt-excerpt.txt$ollama:deepseek-r1:14b</th>\n",
       "      <th>score_location_qid</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_location_string</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_period_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_period_string</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "evaluator                                                                 deepseek:deepseek-reasoner  \\\n",
       "response_id                                        score_name                                          \n",
       "bpt6k10901623$prompt-excerpt.txt$anthropic:clau... score_location_qid                            0.5   \n",
       "                                                   score_location_string                         0.5   \n",
       "                                                   score_period_interval                         0.5   \n",
       "                                                   score_period_string                           1.0   \n",
       "bpt6k10901623$prompt-excerpt.txt$deepseek:deeps... score_location_qid                            0.5   \n",
       "                                                   score_location_string                         0.5   \n",
       "                                                   score_period_interval                         0.0   \n",
       "                                                   score_period_string                           0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee... score_location_qid                            0.0   \n",
       "                                                   score_location_string                         0.5   \n",
       "                                                   score_period_interval                         0.0   \n",
       "                                                   score_period_string                           0.0   \n",
       "\n",
       "evaluator                                                                 anthropic:claude-3-7-sonnet-20250219  \\\n",
       "response_id                                        score_name                                                    \n",
       "bpt6k10901623$prompt-excerpt.txt$anthropic:clau... score_location_qid                                      0.5   \n",
       "                                                   score_location_string                                   0.5   \n",
       "                                                   score_period_interval                                   0.5   \n",
       "                                                   score_period_string                                     0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$deepseek:deeps... score_location_qid                                      0.5   \n",
       "                                                   score_location_string                                   0.5   \n",
       "                                                   score_period_interval                                   0.5   \n",
       "                                                   score_period_string                                     0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee... score_location_qid                                      0.0   \n",
       "                                                   score_location_string                                   0.5   \n",
       "                                                   score_period_interval                                   0.0   \n",
       "                                                   score_period_string                                     0.0   \n",
       "\n",
       "evaluator                                                                 ollama:mistral-small:24b  \\\n",
       "response_id                                        score_name                                        \n",
       "bpt6k10901623$prompt-excerpt.txt$anthropic:clau... score_location_qid                          1.0   \n",
       "                                                   score_location_string                       0.5   \n",
       "                                                   score_period_interval                       0.5   \n",
       "                                                   score_period_string                         0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$deepseek:deeps... score_location_qid                          1.0   \n",
       "                                                   score_location_string                       0.5   \n",
       "                                                   score_period_interval                       0.0   \n",
       "                                                   score_period_string                         0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee... score_location_qid                          0.0   \n",
       "                                                   score_location_string                       0.5   \n",
       "                                                   score_period_interval                       0.0   \n",
       "                                                   score_period_string                         0.0   \n",
       "\n",
       "evaluator                                                                 openai:o1-mini  \\\n",
       "response_id                                        score_name                              \n",
       "bpt6k10901623$prompt-excerpt.txt$anthropic:clau... score_location_qid                0.5   \n",
       "                                                   score_location_string             0.5   \n",
       "                                                   score_period_interval             0.5   \n",
       "                                                   score_period_string               1.0   \n",
       "bpt6k10901623$prompt-excerpt.txt$deepseek:deeps... score_location_qid                0.5   \n",
       "                                                   score_location_string             0.5   \n",
       "                                                   score_period_interval             0.0   \n",
       "                                                   score_period_string               1.0   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee... score_location_qid                0.0   \n",
       "                                                   score_location_string             0.5   \n",
       "                                                   score_period_interval             0.0   \n",
       "                                                   score_period_string               0.0   \n",
       "\n",
       "evaluator                                                                 ollama:gemma3:12b  \n",
       "response_id                                        score_name                                \n",
       "bpt6k10901623$prompt-excerpt.txt$anthropic:clau... score_location_qid                   0.5  \n",
       "                                                   score_location_string                0.5  \n",
       "                                                   score_period_interval                0.5  \n",
       "                                                   score_period_string                  0.5  \n",
       "bpt6k10901623$prompt-excerpt.txt$deepseek:deeps... score_location_qid                   0.5  \n",
       "                                                   score_location_string                0.5  \n",
       "                                                   score_period_interval                0.5  \n",
       "                                                   score_period_string                  0.5  \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee... score_location_qid                   0.5  \n",
       "                                                   score_location_string                0.5  \n",
       "                                                   score_period_interval                0.0  \n",
       "                                                   score_period_string                  0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_llmjudges_scores.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>evaluator</th>\n",
       "      <th>deepseek:deepseek-reasoner</th>\n",
       "      <th>anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <th>ollama:mistral-small:24b</th>\n",
       "      <th>openai:o1-mini</th>\n",
       "      <th>ollama:gemma3:12b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-excerpt.txt$deepseek:deepseek-reasoner</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-excerpt.txt$ollama:deepseek-r1:14b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-excerpt.txt$ollama:deepseek-r1:32b</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-excerpt.txt$ollama:gemma3:12b</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k9807756q$prompt-summary.txt$ollama:gemma3:12b</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k9807756q$prompt-summary.txt$ollama:mistral-small:24b</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k9807756q$prompt-summary.txt$ollama:phi4-mini:latest</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k9807756q$prompt-summary.txt$openai:gpt-4o</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k9807756q$prompt-summary.txt$openai:o1-mini</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "evaluator                                           deepseek:deepseek-reasoner  \\\n",
       "response_id                                                                      \n",
       "bpt6k10901623$prompt-excerpt.txt$anthropic:clau...                         1.0   \n",
       "bpt6k10901623$prompt-excerpt.txt$deepseek:deeps...                         0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...                         0.0   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...                         0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:gemma3:12b                         1.0   \n",
       "...                                                                        ...   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:gemma3:12b                         0.5   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:mistral...                         1.0   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:phi4-mi...                         0.0   \n",
       "bpt6k9807756q$prompt-summary.txt$openai:gpt-4o                             0.5   \n",
       "bpt6k9807756q$prompt-summary.txt$openai:o1-mini                            0.5   \n",
       "\n",
       "evaluator                                           anthropic:claude-3-7-sonnet-20250219  \\\n",
       "response_id                                                                                \n",
       "bpt6k10901623$prompt-excerpt.txt$anthropic:clau...                                   0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$deepseek:deeps...                                   0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...                                   0.0   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...                                   0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:gemma3:12b                                   0.5   \n",
       "...                                                                                  ...   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:gemma3:12b                                   1.0   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:mistral...                                   1.0   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:phi4-mi...                                   0.0   \n",
       "bpt6k9807756q$prompt-summary.txt$openai:gpt-4o                                       0.5   \n",
       "bpt6k9807756q$prompt-summary.txt$openai:o1-mini                                      0.5   \n",
       "\n",
       "evaluator                                           ollama:mistral-small:24b  \\\n",
       "response_id                                                                    \n",
       "bpt6k10901623$prompt-excerpt.txt$anthropic:clau...                       0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$deepseek:deeps...                       0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...                       0.0   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...                       0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:gemma3:12b                       0.5   \n",
       "...                                                                      ...   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:gemma3:12b                       0.5   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:mistral...                       1.0   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:phi4-mi...                       0.0   \n",
       "bpt6k9807756q$prompt-summary.txt$openai:gpt-4o                           0.5   \n",
       "bpt6k9807756q$prompt-summary.txt$openai:o1-mini                          0.5   \n",
       "\n",
       "evaluator                                           openai:o1-mini  \\\n",
       "response_id                                                          \n",
       "bpt6k10901623$prompt-excerpt.txt$anthropic:clau...             1.0   \n",
       "bpt6k10901623$prompt-excerpt.txt$deepseek:deeps...             1.0   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...             0.0   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...             0.5   \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:gemma3:12b             1.0   \n",
       "...                                                            ...   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:gemma3:12b             0.5   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:mistral...             1.0   \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:phi4-mi...             0.0   \n",
       "bpt6k9807756q$prompt-summary.txt$openai:gpt-4o                 0.5   \n",
       "bpt6k9807756q$prompt-summary.txt$openai:o1-mini                0.5   \n",
       "\n",
       "evaluator                                           ollama:gemma3:12b  \n",
       "response_id                                                            \n",
       "bpt6k10901623$prompt-excerpt.txt$anthropic:clau...                0.5  \n",
       "bpt6k10901623$prompt-excerpt.txt$deepseek:deeps...                0.5  \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...                0.0  \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...                0.5  \n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:gemma3:12b                0.5  \n",
       "...                                                               ...  \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:gemma3:12b                0.5  \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:mistral...                1.0  \n",
       "bpt6k9807756q$prompt-summary.txt$ollama:phi4-mi...                0.0  \n",
       "bpt6k9807756q$prompt-summary.txt$openai:gpt-4o                    0.5  \n",
       "bpt6k9807756q$prompt-summary.txt$openai:o1-mini                   0.5  \n",
       "\n",
       "[135 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is to single out one specific score across all evaluators and all documents\n",
    "df_llmjudges_scores.xs('score_period_string', level='score_name', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute correlation between scores by LLM judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_names = df_llmjudges_scores.index.get_level_values('score_name').unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df_llmjudges_scores.xs(score_names[0], level='score_name', axis=0).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>evaluator</th>\n",
       "      <th>deepseek:deepseek-reasoner</th>\n",
       "      <th>anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <th>ollama:mistral-small:24b</th>\n",
       "      <th>openai:o1-mini</th>\n",
       "      <th>ollama:gemma3:12b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evaluator</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deepseek:deepseek-reasoner</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904871</td>\n",
       "      <td>0.854925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <td>0.904871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.808991</td>\n",
       "      <td>0.904871</td>\n",
       "      <td>0.558059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:mistral-small:24b</th>\n",
       "      <td>0.854925</td>\n",
       "      <td>0.808991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854925</td>\n",
       "      <td>0.512800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai:o1-mini</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904871</td>\n",
       "      <td>0.854925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:gemma3:12b</th>\n",
       "      <td>0.587329</td>\n",
       "      <td>0.558059</td>\n",
       "      <td>0.512800</td>\n",
       "      <td>0.587329</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "evaluator                             deepseek:deepseek-reasoner  \\\n",
       "evaluator                                                          \n",
       "deepseek:deepseek-reasoner                              1.000000   \n",
       "anthropic:claude-3-7-sonnet-20250219                    0.904871   \n",
       "ollama:mistral-small:24b                                0.854925   \n",
       "openai:o1-mini                                          1.000000   \n",
       "ollama:gemma3:12b                                       0.587329   \n",
       "\n",
       "evaluator                             anthropic:claude-3-7-sonnet-20250219  \\\n",
       "evaluator                                                                    \n",
       "deepseek:deepseek-reasoner                                        0.904871   \n",
       "anthropic:claude-3-7-sonnet-20250219                              1.000000   \n",
       "ollama:mistral-small:24b                                          0.808991   \n",
       "openai:o1-mini                                                    0.904871   \n",
       "ollama:gemma3:12b                                                 0.558059   \n",
       "\n",
       "evaluator                             ollama:mistral-small:24b  \\\n",
       "evaluator                                                        \n",
       "deepseek:deepseek-reasoner                            0.854925   \n",
       "anthropic:claude-3-7-sonnet-20250219                  0.808991   \n",
       "ollama:mistral-small:24b                              1.000000   \n",
       "openai:o1-mini                                        0.854925   \n",
       "ollama:gemma3:12b                                     0.512800   \n",
       "\n",
       "evaluator                             openai:o1-mini  ollama:gemma3:12b  \n",
       "evaluator                                                                \n",
       "deepseek:deepseek-reasoner                  1.000000           0.587329  \n",
       "anthropic:claude-3-7-sonnet-20250219        0.904871           0.558059  \n",
       "ollama:mistral-small:24b                    0.854925           0.512800  \n",
       "openai:o1-mini                              1.000000           0.587329  \n",
       "ollama:gemma3:12b                           0.587329           1.000000  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(f\"Correlation Matrix Heatmap for {score_names[0]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in human scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_scores = [\n",
    "    prepare_human_scores_dataframe(score_file)\n",
    "    for score_file in (base_path / 'data/validation/human_annotator_scores').glob('*.tsv')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "df_human_scores = reduce(lambda left, right: pd.merge(left, right, on=['response_id', 'score_name'], how='outer'), human_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mr = human_scores[0].xs('matteor', axis=1).reset_index().rename(columns={'matteor':'score_value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sg = human_scores[1].xs('simong', axis=1).reset_index().rename(columns={'simong':'score_value'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute percentage of disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the individual scores where human annotators disagreed\n",
    "diffs = score_mr.compare(score_sg, keep_equal=False).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.41"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the percentage of disagreements between the two human annotators\n",
    "round(diffs.shape[0] * 100 / score_mr.shape[0], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_name\n",
       "period_timeframe_score    19\n",
       "period_string_score       15\n",
       "location_string_score      5\n",
       "location_qid_score         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and these are the scores where the human annotators disagreed\n",
    "# which shows that scores relalted to the time period (both the string and the interval) were the most problematic\n",
    "score_mr.loc[diffs].score_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IAA between human and LLM judge scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_names = df_human_scores.index.get_level_values('score_name').unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['score_location_qid',\n",
       " 'score_location_string',\n",
       " 'score_period_interval',\n",
       " 'score_period_string']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>evaluator</th>\n",
       "      <th>matteor</th>\n",
       "      <th>simong</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-excerpt.txt$anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-excerpt.txt$deepseek:deepseek-reasoner</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-excerpt.txt$ollama:deepseek-r1:14b</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-excerpt.txt$ollama:deepseek-r1:32b</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k10901623$prompt-excerpt.txt$ollama:gemma3:12b</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k9807756q$prompt-summary.txt$ollama:gemma3:12b</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k9807756q$prompt-summary.txt$ollama:mistral-small:24b</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k9807756q$prompt-summary.txt$ollama:phi4-mini:latest</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k9807756q$prompt-summary.txt$openai:gpt-4o</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpt6k9807756q$prompt-summary.txt$openai:o1-mini</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "evaluator                                           matteor  simong\n",
       "response_id                                                        \n",
       "bpt6k10901623$prompt-excerpt.txt$anthropic:clau...      0.5     0.5\n",
       "bpt6k10901623$prompt-excerpt.txt$deepseek:deeps...      0.5     0.5\n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...      0.5     0.5\n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:deepsee...      0.5     0.5\n",
       "bpt6k10901623$prompt-excerpt.txt$ollama:gemma3:12b      0.5     0.5\n",
       "...                                                     ...     ...\n",
       "bpt6k9807756q$prompt-summary.txt$ollama:gemma3:12b      1.0     1.0\n",
       "bpt6k9807756q$prompt-summary.txt$ollama:mistral...      1.0     1.0\n",
       "bpt6k9807756q$prompt-summary.txt$ollama:phi4-mi...      0.5     0.0\n",
       "bpt6k9807756q$prompt-summary.txt$openai:gpt-4o          1.0     1.0\n",
       "bpt6k9807756q$prompt-summary.txt$openai:o1-mini         1.0     1.0\n",
       "\n",
       "[135 rows x 2 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_human_scores.xs(score_names[1], level='score_name', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the numpy array should be in the right shape (M, N) where M is the number of annotators and N is the number of observations\n",
    "scores_array = df_human_scores.xs(score_names[1], level='score_name', axis=0).to_numpy().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 135)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the IAA for score_location_string\n"
     ]
    }
   ],
   "source": [
    "print(f'this is the IAA for {score_names[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9740772863062542)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the IAA between human annotators for `period_string_score`\n",
    "krippendorff.alpha(\n",
    "    reliability_data=scores_array,\n",
    "    level_of_measurement='interval' # as we are dealing with numerical scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def compute_iaa(llm_judge_scores: Dict[str, pd.DataFrame], human_scores: pd.DataFrame) -> None:\n",
    "    iaa_scores = []\n",
    "    score_names = human_scores.index.get_level_values('score_name').unique().to_list()\n",
    "    human_iaa = {\n",
    "            score_name: round(krippendorff.alpha(\n",
    "                reliability_data=human_scores.xs(score_name, level='score_name', axis=0).to_numpy().T,\n",
    "                level_of_measurement='interval' # as we are dealing with numerical scores\n",
    "            ), 3)\n",
    "            for score_name in score_names\n",
    "        }\n",
    "    human_iaa['setting'] = 'hum. ann.'\n",
    "    iaa_scores.append(human_iaa)\n",
    "\n",
    "    for judge in llm_judge_scores.keys():\n",
    "        setting = f'{judge}'\n",
    "        merged_df = human_scores.merge(scores[judge], on=['response_id', 'score_name'], how='outer')\n",
    "        score_names = merged_df.index.get_level_values('score_name').unique().to_list()\n",
    "\n",
    "        iaa = {\n",
    "            score_name: krippendorff.alpha(\n",
    "                reliability_data=merged_df.xs(score_name, level='score_name', axis=0).to_numpy().T,\n",
    "                level_of_measurement='interval' # as we are dealing with numerical scores\n",
    "            )\n",
    "            for score_name in score_names\n",
    "        }\n",
    "        iaa['setting'] = setting\n",
    "        iaa_scores.append(iaa)\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(iaa_scores).set_index('setting')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iaa = compute_iaa(scores, df_human_scores)\n",
    "df_iaa['avg_iaa'] = df_iaa.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_location_qid</th>\n",
       "      <th>score_location_string</th>\n",
       "      <th>score_period_interval</th>\n",
       "      <th>score_period_string</th>\n",
       "      <th>avg_iaa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setting</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hum. ann.</th>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.885750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek:deepseek-reasoner</th>\n",
       "      <td>0.963497</td>\n",
       "      <td>0.944976</td>\n",
       "      <td>0.742505</td>\n",
       "      <td>0.897374</td>\n",
       "      <td>0.887088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <td>0.894255</td>\n",
       "      <td>0.968914</td>\n",
       "      <td>0.805062</td>\n",
       "      <td>0.882317</td>\n",
       "      <td>0.887637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:mistral-small:24b</th>\n",
       "      <td>0.789550</td>\n",
       "      <td>0.968576</td>\n",
       "      <td>0.709896</td>\n",
       "      <td>0.871131</td>\n",
       "      <td>0.834788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai:o1-mini</th>\n",
       "      <td>0.963497</td>\n",
       "      <td>0.978985</td>\n",
       "      <td>0.762952</td>\n",
       "      <td>0.907935</td>\n",
       "      <td>0.903342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:gemma3:12b</th>\n",
       "      <td>0.551415</td>\n",
       "      <td>0.957126</td>\n",
       "      <td>0.693830</td>\n",
       "      <td>0.880665</td>\n",
       "      <td>0.770759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      score_location_qid  \\\n",
       "setting                                                    \n",
       "hum. ann.                                       0.945000   \n",
       "deepseek:deepseek-reasoner                      0.963497   \n",
       "anthropic:claude-3-7-sonnet-20250219            0.894255   \n",
       "ollama:mistral-small:24b                        0.789550   \n",
       "openai:o1-mini                                  0.963497   \n",
       "ollama:gemma3:12b                               0.551415   \n",
       "\n",
       "                                      score_location_string  \\\n",
       "setting                                                       \n",
       "hum. ann.                                          0.974000   \n",
       "deepseek:deepseek-reasoner                         0.944976   \n",
       "anthropic:claude-3-7-sonnet-20250219               0.968914   \n",
       "ollama:mistral-small:24b                           0.968576   \n",
       "openai:o1-mini                                     0.978985   \n",
       "ollama:gemma3:12b                                  0.957126   \n",
       "\n",
       "                                      score_period_interval  \\\n",
       "setting                                                       \n",
       "hum. ann.                                          0.745000   \n",
       "deepseek:deepseek-reasoner                         0.742505   \n",
       "anthropic:claude-3-7-sonnet-20250219               0.805062   \n",
       "ollama:mistral-small:24b                           0.709896   \n",
       "openai:o1-mini                                     0.762952   \n",
       "ollama:gemma3:12b                                  0.693830   \n",
       "\n",
       "                                      score_period_string   avg_iaa  \n",
       "setting                                                              \n",
       "hum. ann.                                        0.879000  0.885750  \n",
       "deepseek:deepseek-reasoner                       0.897374  0.887088  \n",
       "anthropic:claude-3-7-sonnet-20250219             0.882317  0.887637  \n",
       "ollama:mistral-small:24b                         0.871131  0.834788  \n",
       "openai:o1-mini                                   0.907935  0.903342  \n",
       "ollama:gemma3:12b                                0.880665  0.770759  "
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iaa.index = [\n",
    "    label.split(':')[1] if \":\" in label else label\n",
    "    for label in df_iaa.index.to_list()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_location_qid</th>\n",
       "      <th>score_location_string</th>\n",
       "      <th>score_period_interval</th>\n",
       "      <th>score_period_string</th>\n",
       "      <th>avg_iaa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o1-mini</th>\n",
       "      <td>0.963497</td>\n",
       "      <td>0.978985</td>\n",
       "      <td>0.762952</td>\n",
       "      <td>0.907935</td>\n",
       "      <td>0.903342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude-3-7-sonnet-20250219</th>\n",
       "      <td>0.894255</td>\n",
       "      <td>0.968914</td>\n",
       "      <td>0.805062</td>\n",
       "      <td>0.882317</td>\n",
       "      <td>0.887637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek-reasoner</th>\n",
       "      <td>0.963497</td>\n",
       "      <td>0.944976</td>\n",
       "      <td>0.742505</td>\n",
       "      <td>0.897374</td>\n",
       "      <td>0.887088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hum. ann.</th>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.885750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral-small</th>\n",
       "      <td>0.789550</td>\n",
       "      <td>0.968576</td>\n",
       "      <td>0.709896</td>\n",
       "      <td>0.871131</td>\n",
       "      <td>0.834788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemma3</th>\n",
       "      <td>0.551415</td>\n",
       "      <td>0.957126</td>\n",
       "      <td>0.693830</td>\n",
       "      <td>0.880665</td>\n",
       "      <td>0.770759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            score_location_qid  score_location_string  \\\n",
       "o1-mini                               0.963497               0.978985   \n",
       "claude-3-7-sonnet-20250219            0.894255               0.968914   \n",
       "deepseek-reasoner                     0.963497               0.944976   \n",
       "hum. ann.                             0.945000               0.974000   \n",
       "mistral-small                         0.789550               0.968576   \n",
       "gemma3                                0.551415               0.957126   \n",
       "\n",
       "                            score_period_interval  score_period_string  \\\n",
       "o1-mini                                  0.762952             0.907935   \n",
       "claude-3-7-sonnet-20250219               0.805062             0.882317   \n",
       "deepseek-reasoner                        0.742505             0.897374   \n",
       "hum. ann.                                0.745000             0.879000   \n",
       "mistral-small                            0.709896             0.871131   \n",
       "gemma3                                   0.693830             0.880665   \n",
       "\n",
       "                             avg_iaa  \n",
       "o1-mini                     0.903342  \n",
       "claude-3-7-sonnet-20250219  0.887637  \n",
       "deepseek-reasoner           0.887088  \n",
       "hum. ann.                   0.885750  \n",
       "mistral-small               0.834788  \n",
       "gemma3                      0.770759  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iaa.sort_values(by='avg_iaa', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Inter-annotator agreement scores for the LLM judge and human annotators.}\n",
      "\\label{tab:iaa-scores}\n",
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      " & Loc. QID & Loc. Str. & Per. Str. & Per. Interv. & Avg. IAA \\\\\n",
      "\\midrule\n",
      "hum. ann. & 0.94 & 0.97 & 0.74 & 0.88 & 0.89 \\\\\n",
      "deepseek-reasoner & 0.96 & 0.94 & 0.74 & 0.90 & 0.89 \\\\\n",
      "claude-3-7-sonnet-20250219 & 0.89 & 0.97 & 0.81 & 0.88 & 0.89 \\\\\n",
      "mistral-small & 0.79 & 0.97 & 0.71 & 0.87 & 0.83 \\\\\n",
      "o1-mini & 0.96 & 0.98 & 0.76 & 0.91 & 0.90 \\\\\n",
      "gemma3 & 0.55 & 0.96 & 0.69 & 0.88 & 0.77 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_iaa.to_latex(\n",
    "    float_format=\"%.2f\",\n",
    "    multicolumn=True,\n",
    "    header=['Loc. QID', 'Loc. Str.', 'Per. Str.', 'Per. Interv.', 'Avg. IAA'],\n",
    "    caption=\"Inter-annotator agreement scores for the LLM judge and human annotators.\",\n",
    "    label=\"tab:iaa-scores\",\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from textentlib.llm_utils import process_llm_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_llm_responses(base_path / Path(config['validation']['responses_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_path</th>\n",
       "      <th>document_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>model_name</th>\n",
       "      <th>response</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>is_response_valid_json</th>\n",
       "      <th>is_valid_json_recovered</th>\n",
       "      <th>period</th>\n",
       "      <th>period_reasoning</th>\n",
       "      <th>timeframe_start</th>\n",
       "      <th>timeframe_end</th>\n",
       "      <th>location</th>\n",
       "      <th>location_reasoning</th>\n",
       "      <th>location_qid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/mromanel/Documents/UniGe-TextEnt/chrono...</td>\n",
       "      <td>bpt6k10901623</td>\n",
       "      <td>prompt-excerpt.txt</td>\n",
       "      <td>ollama:mistral-small:24b</td>\n",
       "      <td>{\\n  \"period\": \"Middle Ages\",\\n  \"period_reaso...</td>\n",
       "      <td>36.471903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Middle Ages</td>\n",
       "      <td>The title of the play, 'Théodore, Reyne de Hon...</td>\n",
       "      <td>-1000</td>\n",
       "      <td>+1500</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>The title explicitly mentions 'Hongrie', which...</td>\n",
       "      <td>Q27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/mromanel/Documents/UniGe-TextEnt/chrono...</td>\n",
       "      <td>bpt6k10901623</td>\n",
       "      <td>prompt-summary.txt</td>\n",
       "      <td>openai:o1-mini</td>\n",
       "      <td>{\\n    \"period\": null,\\n    \"period_reasoning\"...</td>\n",
       "      <td>7.939035</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>2290.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>The provided information does not specify a hi...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>The title of the play refers to 'Reyne de Hong...</td>\n",
       "      <td>Q28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       response_path    document_id  \\\n",
       "0  /Users/mromanel/Documents/UniGe-TextEnt/chrono...  bpt6k10901623   \n",
       "1  /Users/mromanel/Documents/UniGe-TextEnt/chrono...  bpt6k10901623   \n",
       "\n",
       "            prompt_id                model_name  \\\n",
       "0  prompt-excerpt.txt  ollama:mistral-small:24b   \n",
       "1  prompt-summary.txt            openai:o1-mini   \n",
       "\n",
       "                                            response  duration_seconds  \\\n",
       "0  {\\n  \"period\": \"Middle Ages\",\\n  \"period_reaso...         36.471903   \n",
       "1  {\\n    \"period\": null,\\n    \"period_reasoning\"...          7.939035   \n",
       "\n",
       "   prompt_tokens  completion_tokens  total_tokens  is_response_valid_json  \\\n",
       "0            NaN                NaN           NaN                    True   \n",
       "1         1149.0             1141.0        2290.0                    True   \n",
       "\n",
       "   is_valid_json_recovered       period  \\\n",
       "0                    False  Middle Ages   \n",
       "1                    False         None   \n",
       "\n",
       "                                    period_reasoning timeframe_start  \\\n",
       "0  The title of the play, 'Théodore, Reyne de Hon...           -1000   \n",
       "1  The provided information does not specify a hi...            None   \n",
       "\n",
       "  timeframe_end location                                 location_reasoning  \\\n",
       "0         +1500  Hungary  The title explicitly mentions 'Hongrie', which...   \n",
       "1          None  Hungary  The title of the play refers to 'Reyne de Hong...   \n",
       "\n",
       "  location_qid  \n",
       "0          Q27  \n",
       "1          Q28  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmark_speed = pd.pivot_table(\n",
    "    values='duration_seconds',\n",
    "    columns='model_name',\n",
    "    data=df, aggfunc='mean'\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg_tokens = pd.pivot_table(\n",
    "    values=['prompt_tokens', 'completion_tokens'],\n",
    "    columns='model_name',\n",
    "    data=df, aggfunc='mean'\n",
    ").T.rename(columns={'completion_tokens': 'output_tokens', 'prompt_tokens': 'input_tokens'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <td>252.733333</td>\n",
       "      <td>918.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek:deepseek-reasoner</th>\n",
       "      <td>1109.733333</td>\n",
       "      <td>805.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai:gpt-4o</th>\n",
       "      <td>158.533333</td>\n",
       "      <td>775.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai:o1-mini</th>\n",
       "      <td>888.066667</td>\n",
       "      <td>795.133333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      output_tokens  input_tokens\n",
       "model_name                                                       \n",
       "anthropic:claude-3-7-sonnet-20250219     252.733333    918.933333\n",
       "deepseek:deepseek-reasoner              1109.733333    805.733333\n",
       "openai:gpt-4o                            158.533333    775.133333\n",
       "openai:o1-mini                           888.066667    795.133333"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_per_token = [\n",
    "    {\n",
    "        'model_name': model,\n",
    "        'cost_per_1M_tokens_input': None,\n",
    "        'cost_per_1M_tokens_output': None\n",
    "    }\n",
    "    for model in df_benchmark_speed.index.to_list()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all costs expressed in USD\n",
    "\n",
    "cost_per_hour_baobab = 0.11 # 0.10 CHF = 0.11 USD\n",
    "\n",
    "cost_per_token = [\n",
    "    {\n",
    "        'model_name': 'anthropic:claude-3-7-sonnet-20250219',\n",
    "        'cost_per_hour': None,\n",
    "        'cost_per_1M_tokens_input': 3.0,\n",
    "        'cost_per_1M_tokens_output': 15.0\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'deepseek:deepseek-reasoner',\n",
    "        'cost_per_hour': None,\n",
    "        'cost_per_1M_tokens_input': 0.55, # considering 'cache miss' cost\n",
    "        'cost_per_1M_tokens_output': 2.19\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'ollama:deepseek-r1:14b', \n",
    "        'cost_per_hour': cost_per_hour_baobab,\n",
    "        'cost_per_1M_tokens_input': None,\n",
    "        'cost_per_1M_tokens_output': None\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'ollama:deepseek-r1:32b',\n",
    "        'cost_per_hour': cost_per_hour_baobab,\n",
    "        'cost_per_1M_tokens_input': None,\n",
    "        'cost_per_1M_tokens_output': None\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'ollama:gemma3:12b',\n",
    "        'cost_per_hour': cost_per_hour_baobab,\n",
    "        'cost_per_1M_tokens_input': None,\n",
    "        'cost_per_1M_tokens_output': None\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'ollama:mistral-small:24b',\n",
    "        'cost_per_hour': cost_per_hour_baobab,\n",
    "        'cost_per_1M_tokens_input': None,\n",
    "        'cost_per_1M_tokens_output': None\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'ollama:phi4-mini:latest',\n",
    "        'cost_per_hour': cost_per_hour_baobab,\n",
    "        'cost_per_1M_tokens_input': None,\n",
    "        'cost_per_1M_tokens_output': None\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'openai:gpt-4o',\n",
    "        'cost_per_hour': None,\n",
    "        'cost_per_1M_tokens_input': 2.5,\n",
    "        'cost_per_1M_tokens_output': 10.0\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'openai:o1-mini',\n",
    "        'cost_per_hour': None,\n",
    "        'cost_per_1M_tokens_input': 1.10,\n",
    "        'cost_per_1M_tokens_output': 4.40\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_seconds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <td>5.202731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek:deepseek-reasoner</th>\n",
       "      <td>63.381709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:deepseek-r1:14b</th>\n",
       "      <td>69.133920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:deepseek-r1:32b</th>\n",
       "      <td>156.856872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:gemma3:12b</th>\n",
       "      <td>14.933889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:mistral-small:24b</th>\n",
       "      <td>31.787582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:phi4-mini:latest</th>\n",
       "      <td>11.554595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai:gpt-4o</th>\n",
       "      <td>3.889093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai:o1-mini</th>\n",
       "      <td>6.988482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      duration_seconds\n",
       "model_name                                            \n",
       "anthropic:claude-3-7-sonnet-20250219          5.202731\n",
       "deepseek:deepseek-reasoner                   63.381709\n",
       "ollama:deepseek-r1:14b                       69.133920\n",
       "ollama:deepseek-r1:32b                      156.856872\n",
       "ollama:gemma3:12b                            14.933889\n",
       "ollama:mistral-small:24b                     31.787582\n",
       "ollama:phi4-mini:latest                      11.554595\n",
       "openai:gpt-4o                                 3.889093\n",
       "openai:o1-mini                                6.988482"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmark_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmark = df_benchmark_speed.join(df_avg_tokens).join(pd.DataFrame(cost_per_token).set_index('model_name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>cost_per_hour</th>\n",
       "      <th>cost_per_1M_tokens_input</th>\n",
       "      <th>cost_per_1M_tokens_output</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <td>5.202731</td>\n",
       "      <td>252.733333</td>\n",
       "      <td>918.933333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek:deepseek-reasoner</th>\n",
       "      <td>63.381709</td>\n",
       "      <td>1109.733333</td>\n",
       "      <td>805.733333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.55</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:deepseek-r1:14b</th>\n",
       "      <td>69.133920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      duration_seconds  output_tokens  \\\n",
       "model_name                                                              \n",
       "anthropic:claude-3-7-sonnet-20250219          5.202731     252.733333   \n",
       "deepseek:deepseek-reasoner                   63.381709    1109.733333   \n",
       "ollama:deepseek-r1:14b                       69.133920            NaN   \n",
       "\n",
       "                                      input_tokens  cost_per_hour  \\\n",
       "model_name                                                          \n",
       "anthropic:claude-3-7-sonnet-20250219    918.933333            NaN   \n",
       "deepseek:deepseek-reasoner              805.733333            NaN   \n",
       "ollama:deepseek-r1:14b                         NaN           0.11   \n",
       "\n",
       "                                      cost_per_1M_tokens_input  \\\n",
       "model_name                                                       \n",
       "anthropic:claude-3-7-sonnet-20250219                      3.00   \n",
       "deepseek:deepseek-reasoner                                0.55   \n",
       "ollama:deepseek-r1:14b                                     NaN   \n",
       "\n",
       "                                      cost_per_1M_tokens_output  \n",
       "model_name                                                       \n",
       "anthropic:claude-3-7-sonnet-20250219                      15.00  \n",
       "deepseek:deepseek-reasoner                                 2.19  \n",
       "ollama:deepseek-r1:14b                                      NaN  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(row):\n",
    "    \"\"\"\n",
    "    Calculate cost per 1k document, based on avg. number of input and output tokens,\n",
    "    as calculated by each API.\n",
    "    \"\"\"\n",
    "    if pd.isnull(row['cost_per_hour']):\n",
    "        cost_per_input_token = row['cost_per_1M_tokens_input'] / 1_000_000\n",
    "        cost_input = row['input_tokens'] * cost_per_input_token\n",
    "        cost_per_output_token = row['cost_per_1M_tokens_output'] / 1_000_000\n",
    "        cost_output = row['output_tokens'] * cost_per_output_token\n",
    "        total_cost = cost_input + cost_output\n",
    "        return total_cost * 1_000\n",
    "    else:\n",
    "        total_cost = row['duration_seconds'] * (row['cost_per_hour'] / 3600)\n",
    "        return total_cost * 1_000\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time(row):\n",
    "    return (row['duration_seconds'] * 1_000) / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmark['usd_per_1k_document'] = df_benchmark.apply(\n",
    "    lambda row: calculate_cost(row),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benchmark['hours_per_1k_document'] = df_benchmark.apply(\n",
    "    lambda row: calculate_time(row),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>usd_per_1k_document</th>\n",
       "      <th>hours_per_1k_document</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anthropic:claude-3-7-sonnet-20250219</th>\n",
       "      <td>5.202731</td>\n",
       "      <td>918.933333</td>\n",
       "      <td>252.733333</td>\n",
       "      <td>6.547800</td>\n",
       "      <td>1.445203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepseek:deepseek-reasoner</th>\n",
       "      <td>63.381709</td>\n",
       "      <td>805.733333</td>\n",
       "      <td>1109.733333</td>\n",
       "      <td>2.873469</td>\n",
       "      <td>17.606030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:deepseek-r1:14b</th>\n",
       "      <td>69.133920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.112425</td>\n",
       "      <td>19.203867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:deepseek-r1:32b</th>\n",
       "      <td>156.856872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.792849</td>\n",
       "      <td>43.571353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:gemma3:12b</th>\n",
       "      <td>14.933889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456313</td>\n",
       "      <td>4.148302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:mistral-small:24b</th>\n",
       "      <td>31.787582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.971287</td>\n",
       "      <td>8.829884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ollama:phi4-mini:latest</th>\n",
       "      <td>11.554595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.353057</td>\n",
       "      <td>3.209610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai:gpt-4o</th>\n",
       "      <td>3.889093</td>\n",
       "      <td>775.133333</td>\n",
       "      <td>158.533333</td>\n",
       "      <td>3.523167</td>\n",
       "      <td>1.080304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai:o1-mini</th>\n",
       "      <td>6.988482</td>\n",
       "      <td>795.133333</td>\n",
       "      <td>888.066667</td>\n",
       "      <td>4.782140</td>\n",
       "      <td>1.941245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      duration_seconds  input_tokens  \\\n",
       "model_name                                                             \n",
       "anthropic:claude-3-7-sonnet-20250219          5.202731    918.933333   \n",
       "deepseek:deepseek-reasoner                   63.381709    805.733333   \n",
       "ollama:deepseek-r1:14b                       69.133920           NaN   \n",
       "ollama:deepseek-r1:32b                      156.856872           NaN   \n",
       "ollama:gemma3:12b                            14.933889           NaN   \n",
       "ollama:mistral-small:24b                     31.787582           NaN   \n",
       "ollama:phi4-mini:latest                      11.554595           NaN   \n",
       "openai:gpt-4o                                 3.889093    775.133333   \n",
       "openai:o1-mini                                6.988482    795.133333   \n",
       "\n",
       "                                      output_tokens  usd_per_1k_document  \\\n",
       "model_name                                                                 \n",
       "anthropic:claude-3-7-sonnet-20250219     252.733333             6.547800   \n",
       "deepseek:deepseek-reasoner              1109.733333             2.873469   \n",
       "ollama:deepseek-r1:14b                          NaN             2.112425   \n",
       "ollama:deepseek-r1:32b                          NaN             4.792849   \n",
       "ollama:gemma3:12b                               NaN             0.456313   \n",
       "ollama:mistral-small:24b                        NaN             0.971287   \n",
       "ollama:phi4-mini:latest                         NaN             0.353057   \n",
       "openai:gpt-4o                            158.533333             3.523167   \n",
       "openai:o1-mini                           888.066667             4.782140   \n",
       "\n",
       "                                      hours_per_1k_document  \n",
       "model_name                                                   \n",
       "anthropic:claude-3-7-sonnet-20250219               1.445203  \n",
       "deepseek:deepseek-reasoner                        17.606030  \n",
       "ollama:deepseek-r1:14b                            19.203867  \n",
       "ollama:deepseek-r1:32b                            43.571353  \n",
       "ollama:gemma3:12b                                  4.148302  \n",
       "ollama:mistral-small:24b                           8.829884  \n",
       "ollama:phi4-mini:latest                            3.209610  \n",
       "openai:gpt-4o                                      1.080304  \n",
       "openai:o1-mini                                     1.941245  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_benchmark[['duration_seconds', 'input_tokens', 'output_tokens', 'usd_per_1k_document', 'hours_per_1k_document']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Average LLM processing time (seconds) per document'}, ylabel='Large Language Model (LLM)'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_benchmark_speed.plot(\n",
    "    kind='barh',\n",
    "    figsize=(10, 5),\n",
    "    title='Average LLM processing time (seconds) per document', \n",
    "    fontsize=12,\n",
    "    ylabel='Large Language Model (LLM)',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
